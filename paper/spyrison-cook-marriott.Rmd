---
documentclass: jdssv
classoption: article
output:
  bookdown::pdf_document2:
    keep_tex: true
    toc: false
    template: template/jdssv_template.tex
    #citation_package: natbib
title: "The effect of user interaction for understanding variable contributions to structure in linear projections"
  # formatted: "Casting Multiple Shadows: High-Dimensional Interactive Data Visualisation with Tours and Embeddings"
  # plain:     "Casting Multiple Shadows: High-Dimensional Interactive Data Visualisation with Tours and Embeddings"
  # short:     "\\pkg{liminal}: High-Dimensional Interactive Data Visualisation"
## __formatted: and __plain, and __short not wroking
author: "Nicholas Spyrison, Dianne Cook, Kimbal Marriott"
 # - name: Stuart Lee ## 2 spaces
 #    affiliation: Monash University
 #    # use this syntax to add text on several lines
 #    address: |
 #      | Department of Econometrics and Business Statistics,
 #      | Monash University
 #    email: \email{stuart.lee1@monash.edu}
## __-name: , etc not working
## abstract: >
abstract: | 
  Principal component analysis and other eigenvalue decomposition enjoy wide when it comes to visualizing multivariate spaces. The grand tour adds the continuity of near-by linear projections while moving towards a randomly selected basis. The radial tours keep this continuity of projection space while offering a means of controlling this animation. We perform a between-participant user study evaluating these biplots of the above methods. We measure accuracy and speed for a task of supervised clusters where participants indicate which variables contain the separation between two target clusters. Prolific.co is used to crowdsourced N=108 participants across 648 task evaluations. We vary across 3 dimensions of block parameterizations: location, shape, and data dimensionality. In summary, we find that use of radial tour tends to increase accuracy compared with the alternatives. This increase is relatively large compared with the effect from block dimension, though relatively small compared to the random effect of the participant. The use of the grand tour decreases the time takenm, which is also of modest size compared with the effect of the participant. Participants subjectively prefer to use the radial tour for this task.
preamble: > ## LaTeX preamble, load packages
  \usepackage{amsmath}
  \usepackage{graphicx}
  \usepackage{pdflscape}
  \usepackage{lmodern}
  \usepackage{thumbpdf}
  \usepackage{bm}
  \usepackage{xcolor}
## __formatted: and __plain, and keywords not working
keywords: multivariate data, exploratory data analysis, high dimensional data, data
  visualization, cluster analysis, dimension reduction, data science, user study,
  between users, linear projections, linear embeddings
  # formatted: [dimensionality reduction, high-dimensional data, interactive graphics, t-SNE, grand tour, "\\proglang{R}"]
  # plain:     [dimensionality reduction, high-dimensional data, interactive graphics, t-SNE, grand tour, R]
bibliography: spyrison-cook-marriott.bib
editor_options:
  chunk_output_type: console
---
\bibliography{spyrison-cook-marriott}

```{r setup_paper, include=FALSE}
require("knitr")
require("kableExtra")
require("magrittr")
knitr::opts_chunk$set(
  fig.align = "center",
  echo = FALSE,
  collapse = TRUE,
  message = FALSE,
  warning = FALSE,
  error = FALSE,
  cache = FALSE,
  cache.lazy = FALSE
)

## Yihui hack for fixing an xcolor warning on window.
#### not working
# options(kableExtra.latex.load_packages = FALSE)
# knit_hooks$set(document = function(x) {
#   sub('\\usepackage[]{color}', '\\usepackage{xcolor}', x, fixed = TRUE)
# })
```
```{r EXCLUDEDwritingNotes, include=FALSE,eval=FALSE}
#### EXAMPLE YAML from spinifex_paper R journal YAML
# ---
# author:
  # - name: Nicholas Spyrison
  #   # affiliation: Monash University
  #   # address:
  #   # - Faculty of Information Technology
  #   # email:  nicholas.spyrison@monash.edu
  # - name: Dianne Cook
  #   # affiliation: Monash University
  #   # address:
  #   # - Department of Econometrics and Business Statistics
  #   # email:  dicook@monash.edu
  # - name: Kim Marriott
  #   # affiliation: Monash University
  #   # address:
  #   # - Faculty of Information Technology
  #   # email:  Kim.Marriott@monash.edu
# preamble: > %% LaTeX preamble, load packages
#   \usepackage{amsmath}
# link-citations: true
# fig_caption: yes
# toc: false
# 
# bibliography: spyrison-cook-marriott.bib
# output: rticles::ieee_article
# ---
# \bibliography{spyrison-cook-marriott}

#### Hypothesis: 
# does the availability of the manual tour improve the ability of the analyst 
# to understand the importance of variables contributing to the structure?

#### Other user studies to consider:
## compares iPCA application (PCA, princomp, ensombal graphics vs comercial SAS/INSIGHT)
# DH Jeong 2009
# https://www.researchgate.net/profile/Brian_Fisher2/publication/220506453_IPCA_An_interactive_system_for_PCA-based_visual_analytics/links/59e395fa458515393d5b8f29/IPCA-An-interactive-system-for-PCA-based-visual-analytics.pdf 
# 
# a bit removed, for larger dimensions (100's):
# J Yang 2007  
# https://www.researchgate.net/profile/Matthew_Ward3/publication/6451414_Value_and_Relation_Display_Interactive_Visual_Exploration_of_Large_Data_Sets_with_Hundreds_of_Dimensions/links/00b495320b8f337d3a000000.pdf 
#
# Ben's Data Visceralization
# https://arxiv.org/pdf/2009.00059.pdf

#### inspiration; Other papers from kt, and kadek:
## It's a Wrap: 
## K. Chen et al.
## https://www.researchgate.net/profile/Kun_Ting_Chen2/publication/348620236_It's_a_Wrap_Toroidal_Wrapping_of_Network_Visualisations_Supports_Cluster_Understanding_Tasks/links/6007d5d5a6fdccdcb868b2ef/Its-a-Wrap-Toroidal-Wrapping-of-Network-Visualisations-Supports-Cluster-Understanding-Tasks.pdf
##
## Quantitative Data Visualization on Virtual Globes,
## K. Satriadi et al. Chi2021
## https://www.researchgate.net/profile/Kadek_Satriadi/publication/348706131_Quantitative_Data_Visualisation_on_Virtual_Globes/links/600c1275a6fdccdcb873728a/Quantitative-Data-Visualisation-on-Virtual-Globes.pdf
```

<!-- Example figure -->
```{r EXCLUDEDfigExamp, echo = F, out.width = '100%',fig.cap = "Example case. Person 'A' is assigned to group 2, where they will use factor 2 (grand tour) for the first period. They perform 3 block difficulties of task 1 on simulations of increasing difficulty. Then 3 block difficulties of task 2 on unique simulations sampled from the same distributions of increasing difficulty. After this, they proceed to period 2, where they are use factor 3 (manual tour) to perform 3 block difficulties of each task. Lastly, in the third period, they use factor 1 (PCA) to perform the tasks.", eval = F}
knitr::include_graphics("./figures/imageName.pdf") ## Note relative to the folder that the .rmd is in not the project dir()
```
<!-- Figure \@ref(fig:EXCLUDEDfigExamp) is an example of intext referencing the example figure. -->


# Introduction

<!-- catchy use case -->
Imagine, it is that time of year, again. Your favorite data event is right around the corner. They did a great job tantalizing releasing new information piece by piece. You know the topic, you have your tool belt is at the ready. Your plan of attack is sound and thought-through. But what about the communication, you've seen this before, so-many measures to look at and digest let alone to convey to others. The audience reading your submission also needs to be rapidly brought up to speed on such a complex problem. The visualizations you use can make or break your submission, or more dangerously may even obscure an insight to the author.

<!-- Multivariate spaces and EDA -->
Multivariate data (and measure space) is ubiquitous. Yet exploratory data analysis (EDA) [@tukey_exploratory_1977] of such spaces becomes difficult, increasingly so as dimension increases. Numeric statistic summarization of data often doesn't explain the full complexity of the data or worse can lead to missing obvious visual patterns [@anscombe_graphs_1973; @matejka_same_2017; @goodman_dirty_2008; @coleman_geometric_1986]. Ideally, data would be visually explored, in its original variable-space, before and after model application, and statistical summarization. This is crucial to validating assumptions, identify outliers, finding visual peculiarities, and galvanizing insight in the best direction to take a study.
<!-- Wickham [@wickham_visualizing_2015] introduces the terminologies of data-space. -->

<!-- Research gap -->
Previous user studies in dimension reduction compare across embedding- and display- dimensionality [@wagner_filho_immersive_2018; @gracia_new_2016]. There are empirical metrics and comparisons used to describe non-linear reduction and how well and faithfully they embed the data [@van_der_maaten_visualizing_2008; @sedlmair_empirical_2013; @liu_visualizing_2017]. <!-- Add comment about the ensemble graphics applications of multivariate visuals? -->There is a notable absence comparing linear techniques, finding which excel and under which contexts they should be employed, and when to best convey information to the audience. <!-- We have principles, grammar, and designs, yet these aid and guide composition of 2D plots, sometimes with perception ques into a 3rd spatial dimension, or by mapping variables to aesthetics such as color or shape.Visualizing multivariate data is an appreciable task. Doing so almost implies a trade-off between viewing large numbers of linear projection or highly obscuring and distorting the variable space to fit itself into a low dimension non-linear embedding.--> 

<!-- Add more gap and lit review here? Wants a better segue. -->
Here, we compare and contrast the efficacy of 3 linear projection techniques through the application of a within-participant user study. Specific visualization is the primary factor of the study with a null hypothesis that visual has no impact on the accuracy nor the speed of evaluating a task. We design a task and measure evaluating its accuracy that involves participants indicating which variable(s) contain a difference in groups of different clusters. Data is simulated over several block parameterizations. 


<!-- Not Scatterplot matrices, PCP, want mapped to position -->
<!-- For these reasons, it is important to use visualizations of data spaces and extend the diversity of its application. However, visualizing data containing more than a handful of variables is not trivial. Scatterplot matrices or small multiples [@chambers_graphical_1983] looks at all permutation pairs of variables, but quickly becomes to vast a number of images to consider. On the other extreme, parallel coordinates plot [@ocagne_coordonnees_1885] and its radial variants, plot observations as lines varying across scaled variables as displayed in a line or circle. This scales well with dimensionality, while suffering from couple issues. The larger issue, being the loss of mapping multiple variables to graphic position, which is perhaps the most important visual cue for human perception [@munzner_visualization_2014]. The lesser being that they suffer from asymmetry, as their interpretation is dependent on variable ordering. -->

<!-- linear combinations of dimensions -->
<!-- Using a linear combinations of variables will allow us to keep position in 2 display axes while peering into information not contained in any one dimension. The idea of using a combination of variables may appear daunting at first, however we do it almost exclusively in the spatial dimensions. That is to say we are rarely completely aligned with rectangular objects at any one point in time. Consider a book or a filing cabinet any orientation that isn't fully a 2D rectangle, you are seeing as a linear combination of its variables, height, width, and depth. Generalizing this to arbitrary dimensionality we can project or embed a 2D profile of $p$-dimensional data. Its worth noting that the number of these embedded profiles, and consequently the time it takes to explore them, increase exponentially with the dimensionality of the data. -->

<!-- Exclude non-linear embeddings -->
<!-- Non-linear embeddings, the compliment of the linear embedding, have also been well received recently especially with the emergence of t-Distributed stochastic neighbor embedding [@van_der_maaten_visualizing_2008]. Such techniques distort the fully dimensionality on to a low, typically 2D plane. The issue with doing so is that unit of distance is not consistent with location in the embedded space, which severely hinders the interoperability of these embeddings. Additionally they often have hyperparameters that need tuning. Doing so results in completely different or contradicting embeddings. Suffice it to say we exclude their consideration for such broad application for multivariate EDA. -->

<!-- <!-- nonlinear projections precluded --> 
<!-- More recently there have been advances and fanfare in non-linear projections such as self-organizing maps [@kohonen_self-organizing_1990], and t-SNE [@maaten_visualizing_2008]. Because of the use of non-affine transformations, they offer arbitrary model spaces, without interoperability back to variable space. This precludes them as candidates for exploratory data analysis of the multivariate data in question. They can be useful for the rapid identification of possible candidates for outliers or classifications. However they can suffer from overfitting, and crucially cannot be interpreted in terms of the original variables.   -->

<!-- Exclude class supervised examples -->
<!-- Additionally there are many methods for supervised data, that is, with observation classes known a priori. Linear discriminant analysis [@fisher_use_1936], for instance, is an example of linear projection, which creates it's components based on the mean separation and covariance shape between known classes. Because we which to extrapolate to generalized EDA of multivariate space we will not use any such supervised techniques to initialize components in the study. -->



<!-- structure of the paper -->
Section \@ref(sec:background) discusses the visualization methods. Section \@ref(sec:userstudy) goes into the user study. Subsection \@ref(sec:task) digs into the task and its evaluation. The results of the study are in section \@ref(sec:results). Conclusion and future directions are  covered in section \@ref(sec:conclusion). An accompanying tool is discussed in section \@ref(sec:spinifex).


# Background, visual methods {#sec:background}

<!-- Arriving at linear projections or too meta? -->
<!-- Considering that we want to explore multivariate data space while restricting. -->

## Linear projection notation

Consider a numeric data matrix with $n$ observations of $p$ variables,

\begin{gather*}
  \textbf{X}_{[n, p]} = (\textbf{x}_{1},~...~\textbf{x}_{p}) \\
  \textbf{x}_{i} = (x_{1i},~...~ x_{ni})~|~i \in [1, p]
\end{gather*}

Let $Y_{[n, d]}$ be the $d$-dimensional projection or embedding of $\textbf{X}_{[n, p]}$ via matrix multiplication of a particular orthonormal basis matrix $\textbf{B}_{[p, d]}$.

\begin{gather*}
  \textbf{Y}_{[n, d]} = \textbf{X}_{[n, p]} \textbf{B}_{[p, d]}~|~\textbf{B}\text{ is orthonormal} \\
  \textbf{y}_{j} = (y_{1j},~...~ y_{nj})~|~j \in [i, d]
\end{gather*}

A matrix is said to be orthonormal if and only if they are 1) orthogonal, that is all column pairs are independent, having a cross product of 0, and 2) normal, each column has a norm - Euclidean  distance - of 1.


## Principal component analysis

Principal component analysis is the obvious baseline of comparison for linear projections because of its frequent and broad use across discipline. Principal component analysis (PCA) [@pearson_liii._1901] creates new components that are linear combinations of the original variables. The creation of these variables is ordered by decreasing variation which is orthogonally constrained to all previous components. While the full dimensionality is intact, the benefit comes from the ordered nature of the components. The first two or three components are typically used to approximate the variation multivariate data set, while the rest are discarded. We will allow participants to choose the components on the $x$ and $y$ axes from the first 4 principal components.

## Data visualization tours

<!-- tours intro -->
A data visualization _tour_ is an animation of many linear projections across several identified target bases. One of the key features of the tour is the object permanence of the data points; that is to say by watching nearby frames one can track the relative changes of observations as the basis moves toward the next target basis. Various types of tours are enumerated by the selection or generation of their basis paths[cook_grand_2008; lee_review_2021]. To contrast with PCA, we compare with the _grand_ and _radial_ tours. Both of these methods use geodesically-interpolated orthonormal frames with a fixed step distance between frames.

## Grand tours
<!-- Grand tour -->
In a grand tour[@asimov_grand_1985] the target bases are selected randomly. The grand tour is the first and most widely known tour. It will serve as an intermediate unit of comparison which has continuity of data points in nearby frames along with the radial tour, but lacks the user control enjoyed by PCA and radial tours. This lack of control makes grand tours more of a generalist exploratory tool theoretically wouldn't excel at tasks with a pointed goal in mind.


## Radial, (manual) tours

<!-- Manual tour -->
The _manual_ tour [@cook_manual_1997; @spyrison_spinifex_2020] defines its basis path by manipulating the basis contribution of a selected variable. A manipulation dimension is appended onto the projection plane, with a full contribution given to the selected variable. The target bases are then selected based on rotating this newly created manipulation space. The target bases are then similarly orthogonally-interpolated, data projected and rendered into an animation. In order for the variables to remain independent of each other, the contributions of the other variables must also change, _ie._ dimension space should maintain its orthonormal structure. A key feature of the manual tour is that it affords users a way to control the variable contributions of the next target basis. This means that such manipulations can be selected and queued in advance or select on the spot for human-in-the-loop analysis [@karwowski_international_2006]. However, this navigation is relatively time-consuming due to the huge volume of $p$-space (an aspect of the curse of dimensionality [@bellman_dynamic_1957]) and the abstract method of steering the projection basis. It is advisable to first identify a basis of particular interest and then use a manual tour as a finer, local exploration tool to observe how the contributions of the selected variable do or do not contribute to the feature of interest.

<!-- radial tour variant -->
To simplify the task and keep its duration realistic, we consider a variant of the manual tour, called a _radial_ tour. In a radial tour, the selected variable is allowed to change its magnitude of contribution, but not its angle; it must move along the direction of its original contribution radius. The radial tour benefits from both continuity of the data alongside grand tours, but also allows for user interaction similar to PCA.

<!-- \begin{landscape} -->
```{r figFactor, echo = F, out.width = '100%',fig.cap = "Example of the different visual factors. All use the same sort of biplot display to view linear projections of multivariate data. They differ in which bases are viewed which is influenced by the different factor inputs and whether or not are animated to convey the continuity of data points from 1 frame to the next."}
if(F)
  file.edit("./paper/R/fig_factor.r")
knitr::include_graphics("./figures/figFactor.pdf")
```
<!-- \end{landscape} -->

Figure \@ref(fig:figFactor) illustrates the different visualization factors, the control of biplot aesthetics, and where they differ. The leftmost column discusses their differences alongside 3 of their character bases, albeit it is more difficult to see the benefit of animation in print.

# User study {#sec:userstudy}

## Hypothesis {#sec:hypothesis}

The research question we are trying to answer is: <!-- Research question --> _Does the animated removal of single variables via the radial tour improve the ability of the analyst to understand the importance of variable's contribution to the separation of clusters?_ We measure the accuracy and speed over 4 dimensions of block parameterization. The Null hypotheses can be stated as:

<!-- Hypothesis: null and alternative -->
1, Accuracy) $\\$
$~~~~~~H_0: \text{visualization factor does not impact task accuracy} \\$
2, Speed) $\\$
$~~~~~~H_0: \text{visualization factor does not impact task speed} \\$

<!-- Rational for standards of comparison -->
PCA will be used as a baseline for comparison as it is the most common linear embedding. The grand tour will act as a secondary control that will help evaluate the benefit of animation, where the object permanence of the data points, but without the ability to influence its path. Lastly, the radial tour should perform best as it benefits both from animation and being able to select an individual variable to change the contribution of. 

\begin{center}
\begin{tabular}{ c | p{2.2cm} p{2.2cm} }
factor & observation \newline permanence & user \newline interaction \\
\hline
pca &  & Yes \\
grand & Yes &  \\
radial & Yes & Yes \\
\end{tabular}
\end{center}


## Task and evaluation {#sec:task}

<!-- Geom, clusters, explicit task -->
The display was a 2D scatterplot with observations supervised. Cluster membership was mapped to shape and color. There were either 3 or 4 clusters each with the number of observations within each cluster. Participants were asked to 'check any/all variables that contribute more than average to the cluster separation green circles and orange triangles', which was further explained in the explanatory video as 'mark and all variable that carry more than their fair share of the weight, or 1 quarter in the case of 4 variables'.

<!-- Instruction and video -->
The instructions iterated several times in the video was: 1) Use the input controls to find a frame that contains separation between the clusters of green circles and orange triangles, 2) look at the orientation of the variable contributions in the gray circle, a visual depiction of basis, and 3) select all variables that contribute more than average in the direction of the separation in the scatterplot. Regardless of factor and block values participants were limited to 60 seconds for each evaluation of this task.

<!-- Evaluating measure -->
The evaluation measure of this task was designed with a couple of features in mind: 1) the sum of squares of the individual variable marks should be 1, and 2) symmetric about 0. With these in mind, we define the following measure for evaluating the task.

Let a dataset $\textbf{X}$ be a simulation containing clusters of observations of different distributions. Let $\textbf{X}_k$ be the subset of observations in cluster $k$ containing the $p$ variables.

\begin{align*}
  &\textbf{X}_{[n,~p]} = (x_1,~...~x_p) \\
  &\textbf{X}_{[n_k,~p]k} = (x_1,~...~x_p)
    ~|~ n_k \in [1, n], \text{ is an observation subset of } \textbf{X}
\end{align*}

where

\begin{align*}
  x_{i, j, k} \text{ is scalar; the observation } i \in (1,~...~n),
    \text{ of variable } j \in (1,~...~p), \text{ of cluster } k \in (1,~...~K)
\end{align*}

<!-- W, weights -->
We define weights, $W$ to be a vector explaining the variable-wise difference between 2 clusters. Namely the difference of each variable between clusters, as a proportion of the total difference, less $1/p$ the amount of difference each variable would hold if it were uniformly distributed. <!-- R, participant responses -->Participant responses, $R$ are a vector of logical values, whether or not participant thinks the variable separates the two clusters more than if the difference were uniformly distributed. Then $M$ is a vector of variable marks.

\begin{align*}
W &=\frac
{(\overline{X_{j=1, k=1}} - \overline{X_{j=1, k=2}}, ~...~
(\overline{X_{j=p, k=1}} - \overline{X_{j=p, k=2}})}
{\sum_{j=1}^{p}(|\overline{X_{j,k=1}} - \overline{X_{j,k=2}}|)}
- \frac{1}{p} \\
&= (w_1,~...~ w_p) \\
\\
M &= I(r_j) * sign(w_j) * \sqrt{|w_j|} \\
&= (m_1, ~...~ m_p) \\
\end{align*}

where $I$ is the indicator function. Then the total marks for this task is the sum of this marks vector.

```{r, figBiplotScoring, echo = F, out.width = '100%', fig.cap = "(L), PCA biplot of the components showing the most cluster separation with (R) illustration of the magnitude of cluster separation is for each variable (wide bar) and the weight of the marks given if a variable is selected (red/green line). The horizontal dashed line is 1 / dimensionality, the amount of separation each variable would have if evenly distributed. The weights equal the signed square of the difference between each variable value and the dashed line."}
if(F)
  file.edit("./paper/R/fig_biplot_scoring.r")
knitr::include_graphics("./figures/figBiplotScoring.pdf")
```

<!--Period order: Training, eval, eval -->
Each of the 3 periods introduced the participant to a new factor, where participants were first able to explore an untimed task with data under the simplest parameterizations. The training allows the participant to become familiar with the inputs and visual specific to the factor. Upon clicking a button to proceed text containing the correct answer displays with visual still intact to explore further. After the training, each participant performed 2 evaluation trials. After 60 seconds the display was turned off, though few participants elapsed this time. These evaluation trials were performed under different parameterizations as explained in section \@ref(sec:blocks).


## Factor application {#sec:factors}

<!-- Background for methodology, application here -->
Section \@ref(sec:background) gives the sources and a description of the visual factors PCA, grand tours, and radial manual tours. The factors are tested within-participant, with each factor being evaluated by each participant. The order that factors are experienced in is controlled with the block assignment as illustrated below in Figure \@ref(fig:figParmeterizationExample). Below we cover the aesthetic standardization, as well the unique input and display within each factor.

<!-- aesthetic standardization -->
The visualization methods were standardized wherever possible. each factor was shown as a biplot, with variable contributions displayed on a unit circle. All aesthetic values (colors, shapes, sizes, absence of legend, and absence axis titles) were held consistent. Variable contributions were always shown left of the scatterplot embeddings with their aesthetic values consistent as well. What did vary between factors were their inputs which caused a discrete jump to another pair or principal components, were absent for the grand tour with target bases to animate through selected at random, or for the radial tour which variable should have its contribution animated. Key frames of each factor have been illustrated above in Figure \@ref(fig:figFactor).

<!-- PCA -->
PCA inputs allowed for users to select between the top 4 principal components for both the x and y-axis regardless of the data dimensionality (either 4 or 6). <!-- Grand tours -->There was no user input for the grand tour, users were instead shown a 15-second animation of the same randomly selected path. Users were able to view the same clip up to 4 times within the time limit. <!-- Radial tours -->Radial tours were also displayed at 5 frames per second within the interpolation step size of 0.1 radians. Users were able to swap between variables, upon which the display would change the start of radially increasing the contribution of the selected variable till it was full, zeroed, and then back to its initial contribution. The complete animation of any variable takes about 20 seconds and is almost fully in the projection frame at around 6 seconds. The starting basis of each is initialized to a half-clock design, where the variables were evenly distributed in half of the circle which is then orthonormalized. This design was created to be variable agnostic while maximizing the independence of the variables.


## Blocks and parameterization {#sec:blocks}

<!-- volume of parameter space -->
In addition to visual factor, we vary the data across 3 aspects: 1) The location of the difference between clusters, by mixing a signal and a noise variable at different ratios, we control which variables contain cluster separation, 2) the shapes of the clusters, by changing the variance-covariance matrices, and 3) the dimensionality of the data.

<!-- Dimensionality -->
Dimensionality is tested at 2 modest levels, namely, in 4 dimensions containing 3 clusters and 6 dimensions with 4 clusters. Each cluster samples 140 observations. Each dimension is originally distributed as $\mathcal{N}(2 * I(signal), 1)~|~\text{covariance}~\Sigma$, before applying location mixing and standardizing by standard deviation). Signal variables have a correlation of 0.9 when they have equal orientation and -0.9 when their orientations vary. Noise variables were restricted to 0 correlation. Within each factor-period dimension is fixed with increasing difficulty, 4 then 6.

<!-- Shape, vc matrix -->
For choosing the shape of the clusters we follow the convention given by Scrucca, [@scrucca_mclust_2016] who named and categorize 14 variants of model families containing 3 clusters. The name of the model family is the abbreviation of its respective volume, shape, and orientation, which are either equal or vary. We use the models EEE, EEV, and EVV, the latter is further modified by moving 4 fifths of the data out in a "V" or banana-like shape. Figure \@ref(fig:figModelFamilies) shows the principal component biplot of the 3 model variants applied here. The training always uses 4 dimensions, while the 2 evaluations always contain 4 and 6 dimensions in the order of increasing difficulty. The evaluation periods use EEE, EEV, and EVV-banana respectively in increasing order of difficulty.

```{r figModelFamilies, echo = F, out.width = '100%', fig.cap = "Ellipses of the isodensity of the model families used. Family labels are are the abbreviation for the clusters volume, shape, and orientation respectively, which are either equal or vary. We further change the EVV model by shifting fifths of the data in banana or chevron arrow shape."}
if(F)
  file.edit("./paper/R/fig_model_families.r")
knitr::include_graphics("./figures/figModelFam.pdf")
```

<!-- Location mixing -->
The separation of any pair of clusters is currently contained fully within a single variable at this point. To test the sensitivity to this we mix a noise variable with the signal-containing variable such that the difference in the clusters is mixed at the following percentages: 0/100 (not mixed), 33/66, 50/50 (evenly mixed). The training always uses 4 dimensions, while the 2 evaluations always contain 4 and 6 dimensions in order of increasing difficulty. The training data does not mix signal Location mixing within an evaluation period is held constant and rotated through the 6 permutations of their order. Randomizing the order of the location mixing is controlled by iterating once after each of the 6-factor order permutations are evaluated. This is illustrated in Figure \@ref(fig:figParmeterizationExample).

```{r figParmeterizationExample, echo = F, out.width = '100%', fig.cap = "Illustration of how a hypothetical participant 63 is assigned factor and block parameterizations. Each of the 6-factor order permutations is exhausted before iterating to the next permutation of location order."}
knitr::include_graphics("./figures/figParmeterizationExample.png") ## this is .pttx screen cap, .png ok.
```

<!-- Eval evaluation, selection of size -->
With this setup, we test the parameter space $dimension \in (4,~ 6),~shape \in(EEE,~ EEV,~ EVV-banana),~location ~\in~ (0/100,~ 33/66,~ 50/50)$ percent noise/signal mixing to evaluate the graphic display across the $factors~\in~(PCA,~grand,~radial).$ As we iterate through the possible permutations of these factors and location we perform an even evaluation of the full parameter space every 36 participants. Via pilot studies we estimate that 3 even block evaluations should be sufficient to identify the difference between the factors; we targeted for $N = 108$ participants.

<!-- Learning effect -->
In addition to the explicitly controlled block parameters, we will also be discussing each participant's evaluation order regardless of factor or location experiences. This will expose a learning effect from the repetition of being exposed to this data or problem. Keep in mind that the shape and location are always experienced in order of increasing difficulty.


## Post-study survey {#sec:survey}

<!-- placement and Likert scale -->
After the evaluation section of the study, participants were given a short survey containing questions gauging demographics, experience, and subjective evaluation of each factor on a 5-point Likert scale. The questions and possible responses are as follows:

__Demographic:__ $\\$
- What are your preferred pronouns? [decline to answer, he/him, she/her, they/them or other]
- Which age group do you belong to? [decline to answer, 18 to 24, 25 to 35, 36 to 45, 45 to 60, 60 and up]
- What is your highest completed education? [decline to answer, Undergraduate degree (BA/BSc/other), Graduate degree (MA/MSc/MPhil/other), Doctorate degree (PhD/other); prolific.co participants were filtered to those stating they had at least an undergraduate degree]

<!-- __Within participant bias:__ $\\$ -->
<!-- Likert scale [1-5], least agreement to most agreement. -->

<!-- - I understand how to perform the task. -->
<!-- - I am experienced with data visualization. -->
<!-- - I am educated in multivariate statistical analysis. -->

__Subjective by factor:__ $\\$
- I was already familiar with visualization.
- I found this visualization easy to use.
- I felt confident in my answers with this visualization.
- I liked using this visualization.
<!-- see Tory 2006 for example of ease/confidence/likeability -->


## Sampling population {#sec:population}

We recruited $N = 108$ via prolific.co [@palan_prolific_2018]. We make the assumption that interpretation of biplot displays used will not be commonly used for consumption by the general population and apply a single filter on education; that participants have completed at least an undergraduate degree (some 58,700 of the 150,400 users at the time). There is also the implicit filter that Prolific participants must be at least 18 years of age. Participants were compensated for their time at \pounds 7.50 per hour, whereas the mean duration of the survey was about 16 minutes. We can't preclude previous knowledge or experience with the factors, but instead, try to control for this in the user study. Figure \@ref(fig:figSurveyDemographics) shows distributions of age and preferred pronouns of the participants that completed the post-study survey who are relatively young and well educated.

```{r, figSurveyDemographics, echo = F, out.width = '100%', fig.cap = "Heatmaps of participant demographics, counts of age group by completed education as faceted across preferred pronoun. The average participant was a young adult with an undergraduate or graduate degree."}
if(F) ## Creation and saving figure at:
  file.edit("./paper/R/fig_population_demographics.r")
knitr::include_graphics("./figures/figSurveyDemographics.pdf")
```

## Evenness of block evaluation

From pilot studies through a sample of convenience (consisting of information technology and statistics Ph.D. students attending Monash University) we predict that we wanted 3 even block evaluations to support differences in our factor and block parameterizations. Given that factor and location each have 6 permutations we targeted $N = 108 = 3 * (6 * 6)$ evaluations before data were collected. In data collection, we experienced several adverse conditions, primarily: limited control of application server network configuration, throughput thresholds on data read/write API, and repeat attempts from users when experiencing disconnects. To mitigate this we over-collect survey trials, exclude all partial trials, and remove the oldest attempts (mostly likely to experience adverse network conditions) from over evaluated permutations until we have our desired evaluations under each permutation.

## Data capture and processing

Data was recorded by a \pkg{shiny} application and was written to a Google Sheet at the completion of each study period. Time is measured as the CPU time of the server. This could be made slightly more accurate by calculating the difference of system time at these points. Because the frequency of the participants from prolific was more then the server would handle, participants were manually accepted one or two at a time. We collected participants till we had 3 even evaluations. The processing steps were fairly minimal after formatting to tidy format and decoding values to a more human-readable state. After formatting, a flag is added to indicate if the survey had data from all 3 periods. We remove all partial studies and keep only the last 3 complete studies within each block parameterization, the studies which should have experienced the least adverse network conditions. This brings us to the 108 studies described in the paper, from which models and aggregation tables were built. The post-study surveys were similarly decoded to human-readable tidy format and then filtered to include only those 84 surveys that were associated with the final 108 studies. 

The code, response files, their analyses, and the study application are publicly available at on GitHub [github.com/nspyrison/spinifex_study](https://github.com/nspyrison/spinifex_study).


# Results {#sec:results}

To recap, the primary response variable is task marks as defined in section \@ref(sec:task), and the log of response time will be used as a secondary response variable. We have 2 primary data sets; the user study evaluations and post-study survey. The former is contains the 108 trials with explanatory variables: _factor_, _location_ of the cluster separation signal, the _shape_ of variance-covariance matrix, and the _dim_-ensionality of the data. Block parameterization and randomization was discussed in section \@ref(sec:blocks). The survey was completed for 84 of these 108 trials and contains demographic information (preferred pronoun, age, and education), and subjective measures for each of the factors (*preference*, *familiarity*, *ease of use*, and *confidence*). The survey was covered in more detail in \@ref(sec:survey).

Below we look at the marginal performance of the block parameters and survey responses. After that, we build a battery of regression models to explore the variables and their interactions. Lastly, we look at the subjective measures between the factors.


## Random effect regression against marks

<!-- Note that we list the measures at the top of the Results section -->
<!-- Introduce regression model explaining marks, and the random effect term  -->
To more thoroughly examine explanatory variables we regress against marks. All models have a random effect term on the participant, which captures the effect of the individual participant. After we look at models of the block parameters we extend to compare against survey variables. Last, we compare how adding a random effect for data and regressing against time till last response fares against benchmark models. The matrices for models with more than a few terms quickly become rank deficient; there is not enough information in the data to explain all of the effect terms. In which case the least impactful terms are dropped.

<!-- Building a battery of models -->
In building a set of models to test we include all single term models, a model with all independent terms. We also include an interaction term of factor by location, allowing for the slope of each location to change across each level of the factor, which is feasible. For comparison, an overly complex model with many interaction terms is included.

<!-- _Context: 648 task evaluations from 108 studies; we regress against marks using block parameters_ -->
<!-- 1) Eval parameters -->
$$
\begin{array}{ll}
\textbf{Fixed effects:}          &\textbf{Expanded Mode:} \\
\alpha                           &\widehat{marks} = \mu + \alpha_i + \textbf{Z} + \textbf{W} + \epsilon \\
\alpha + \beta + \gamma + \delta &\widehat{marks} = \mu + \alpha_i + \beta_j + \gamma_k + \delta_l + \textbf{Z} + \textbf{W} + \epsilon \\
\alpha * \beta + \gamma + \delta &\widehat{marks} = \mu + \alpha_i * \beta_j + \textbf{Z} + \textbf{W} + \epsilon \\
\alpha * \beta * \gamma + \delta &\widehat{marks} = \mu + \alpha_i * \beta_j * \gamma_k + \textbf{Z} + \textbf{W} + \epsilon \\
\alpha * \beta * \gamma * \delta &\widehat{marks} = \mu + \alpha_i * \beta_j * \gamma_k * \delta_l + \textbf{Z} + \textbf{W} + \epsilon
\end{array}
$$
$$
\begin{array}{ll}
\text{where } &\mu \text{ is the intercept of the model including the mean of random effect} \\
&\epsilon   \sim \mathcal{N}(0,~\sigma), \text{ the error of the model} \\
&\textbf{Z} \sim \mathcal{N}(0,~\tau), \text{ the random effect of participant} \\
&\textbf{W} \sim \mathcal{N}(0,~\upsilon), \text{ the random effect of simulation} \\
&\alpha_i \text{, fixed term for factor}~|~i\in (\text{pca, grand, radial}) \\
&\beta_j  \text{, fixed term for location}~|~j\in (\text{0\_1, 33\_66, 50\_50}) \text{ \% noise/signal mixing} \\
&\gamma_k \text{, fixed term for shape}~|~k\in (\text{EEE, EEV, EVV banana}) \text{ model shapes} \\
&\delta_l \text{, fixed term for dim}~|~l\in (\text{4 variables \& 3 cluster, 6 variables \& 4 clusters}) \\
\end{array}
$$

```{r marksCompTbl, fig.cap = "Use the caption arg in kable(), not this."}
if(F) ## Creation and saving at:
  file.edit("./apps_supplementary/v4_prolifico_100/_analysis.rmd")
model_comp_tbl_ls <- readRDS("./figures/modelCompLs.rds")
model_comp_tbl_ls[[1]]$`Fixed effects` <- model_comp_tbl_ls[[2]]$`Fixed effects` <-
  c("a", "a+b+c+d", "a*b+c+d", "a*b*c+d", "a*b*c*d")
## 1) Eval parameters
kableExtra::kbl(
  model_comp_tbl_ls[[1]], align = c("l", rep("r", 7)),
  booktabs = TRUE, linesep = "", caption = "Model comparison of our random effect models regressing marks. Each model includes a random effect term of the participant, which explains the individual's influence on their marks. Complex models perform better in terms of R2 and RMSE, yet AIC and BIC penalize their large number of fixed effect in favor of the much simpler model containing only factor.") %>%
  kableExtra::column_spec(column = 1, width = "1.5cm") %>%
  column_spec(column = c(2:3), width = "1cm") %>%
  column_spec(column = c(4:8), width = "1.5cm") %>%
  kable_styling(bootstrap_options = "striped", font_size = 10)
```

<!-- Select model ABcd -->

<!-- Coefficients of the selected model, ABcd -->
```{r marksCoefTbl, fig.cap = "Use the caption arg in kable(), not this."}
if(F) ## Creation and saving at:
  file.edit("./apps_supplementary/v4_prolifico_100/_analysis.rmd")
coef_ls <- readRDS("./figures/modelCoefLs.rds")
rownames(coef_ls[[1]]) <- rownames(coef_ls[[2]]) <-
  c("(Intercept)" ,"fct=grand" ,"fct=radial"
    ,"loc=33_66"  ,"loc=50_50" ,"shp=EEV"
    ,"shp=ban"    ,"dim=6"     ,"fct=grand:loc=33_66"
    ,"fct=radial:loc=33_66"    ,"fct=grand:loc=50_50", "fct=radial:loc=50_50")

## For grouping rows see:
if(F)
  browseURL("https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html#Group_rows_via_labeling")
kableExtra::kbl(coef_ls[[1]], booktabs = TRUE, linesep = "", format = "latex",
                caption = "The model coefficients for $\\widehat{marks} = \\alpha * \\beta + \\gamma + \\delta$, with factor=pca, location=0/100, and shape=EEE held as baselines. Factor being radial is the fixed term with the strongest evidence in support of the hypothesis. When crossing factor with location radial performs worse with 33/66 percent mixing relative to the PCA with no mixing. The model fit is based on the 648 evaluations by the 108 participants.") %>%
  kableExtra::column_spec(column = 1, width = "5cm") %>%
  kableExtra::column_spec(column = 3, width = "1.6cm") %>%
  kableExtra::column_spec(column = c(2, 4:6), width = "1.4cm") %>%
  kableExtra::pack_rows("factor", 2, 3) %>%
  pack_rows("fixed effects", 4, 8) %>%
  pack_rows("interactions", 9, 12) %>%
  kable_styling(bootstrap_options = "striped", font_size = 10)
```

<!-- Random effects vs Mean Mark CI by participant and sim -->
Residual plots have no noticeable non-linear trends and contain striped patterns as an artifact from regressing on discrete variables. Figure \@ref(fig:figEffectRange) illustrates (T) the effect size of the random terms participant and simulation, or more accurately, the 95\% CI from Gelman simulation of their posterior distribution. The effect size of the participant is much larger than simulation. The most extreme participants are statistically significant at $\alpha = .95$, while none of the simulation effects significantly deviate from the null of having no effect size on the marks. In comparison, (B) 95\% confidence intervals of the mean marks for participation and simulation respectively.

```{r figEffectRange, out.width="100%", fig.show='asis', fig.cap="(T) Estimated effect ranges of the random effect terms participant and data simulation of the $\\alpha * \\beta + \\gamma + \\delta$ model. Confidence intervals are created with Gelman simulation on the effect posterior distributions. The effect size of the participant is relatively large, with several significant extrema. None of the simulations deviate significantly. (B) The ordered distributions of the CI of mean marks follow the same general pattern and give the additional context of how much variation is in the data, an upper limit to the effect range. The effect ranges capture about 2/3 of the range of the data without the model. All intervals for $\\alpha = .95$ confidence."}
if(F) ## Creation and saving figure at:
  file.edit("./apps_supplementary/v4_prolifico_100/_analysis.rmd")
knitr::include_graphics("./figures/figEffectRange.pdf")
```

<!-- Conditional effects of variables -->
We also want to visually explore the conditional variables in the model. Figure \@ref(fig:figMarksABcd) explores violin plots of marks by factor while faceting on the location (vertical) and shape (horizontal). Radial tends to increase the marks received, and especially so when there is no signal/noise mixing. 

```{r, figMarksABcd, echo = F, out.width = '100%', fig.cap = "Violin plots of terms of the model $\\widehat{marks} = \\alpha * \\beta + \\gamma + \\delta$. Overlaid with global significance from the Kruskal-Wallis test, and pairwise significance from the Wilcoxon test, both are non-parametric, ranked sum tests suitable for handling discrete data. Participants are more confident and find the radial easier to use relative to the grand tour. Participants claim low familiarity as we expect from crowdsourced participants. Radial is more preferred compared with either alternative for this task."}
if(F) ## Creation and saving figure at:
  file.edit("./apps_supplementary/v4_prolifico_100/_analysis.rmd")
knitr::include_graphics("./figures/figMarksABcd.pdf")
```

## Time regressing models

As a secondary explanatory variable, we also want to look at time. First, we take the log transformation of time as it is right-skewed. Now we repeat the same modeling procedure, namely: 1) build a battery of all additive and multiplicative models. 2) Compare their performance, reporting some top performers. 3) Select a model to examine its coefficients.


```{r timeCompTbl, fig.cap = "Use the caption arg in kable(), not this."}
## 1) Eval parameters
kableExtra::kbl(model_comp_tbl_ls[[2]], align = c("l", rep("r", 7)),
             booktabs = TRUE, linesep = "", caption = "Model comparisons for $\\widehat{log(time)}$ random effect models, where each model includes random effect terms for participants and simulations. We see the same trade-off where the simplest factor model is perferred by AIC/BIC, while R2 and RMSE perform best with the full multiplicative model. We again select the model $\\alpha * \\beta + \\gamma + \\delta$ to explore further as it has relatively high marginal R2 while having much less complexity than the full model.") %>%
  kableExtra::column_spec(column = 1, width = "1.5cm") %>%
  column_spec(column = c(2:3), width = "1cm") %>%
  column_spec(column = c(4:8), width = "1.5cm") %>%
  kable_styling(bootstrap_options = "striped", font_size = 10)
```

```{r timeCoefTbl, fig.cap = "Use the caption arg in kable(), not this."}
kableExtra::kbl(coef_ls[[2]], booktabs = TRUE, linesep = "", format = "latex",
                caption = "The model coeffients for $\\widehat{log(time)} = \\alpha * \\beta + \\gamma + \\delta$, with factor:pca, locaation0/100, and shapeEEE held as baselines. location50/50 is the fixed term with the strongest evidence and takes less time. In contrast, the interaction term location=50/50:shape=EEV has the most evidence and takes much longer on average.") %>%
  kableExtra::column_spec(column = 1, width = "5cm") %>%
  kableExtra::column_spec(column = 3, width = "1.6cm") %>%
  kableExtra::column_spec(column = c(2, 4:6), width = "1.4cm") %>%
  kableExtra::pack_rows("factor", 2, 3) %>%
  pack_rows("fixed effects", 4, 8) %>%
  pack_rows("interactions", 9, 12) %>%
  kable_styling(bootstrap_options = "striped", font_size = 10)
```

```{r figTeffectRange, out.width="100%", fig.show='asis', fig.cap='(T) The effect ranges of Gelman resimulation on posterior distributions. These show the magnitude and distributions of particular participants and simulations. Simulation has a relatively small effect on response time. (B) Confidence intervals for mean log(time) by participant and simulation. The marginal density shows that the response times are left-skewed after log transformation. Interpreting back to linear time there is quite the spread of response times: $e^{1}=2.7$, $e^{2.75}=15.6$, $e^{3.75}=42.5$ seconds. Considering simulations, on the right, the bottom has a large variation of time, relative to the effect ranges which means that the variation actually is explained in the terms of the model and not by the simulation itself.'}
if(F) ## Creation and saving figure at:
  file.edit("./apps_supplementary/v4_prolifico_100/_analysis.rmd")
knitr::include_graphics("./figures/figTeffectRange.pdf")
```

## Subjective measures

The 84 evaluations of the post-study survey also collect 4 subjective measures for each factor. Figure \@ref(fig:figSubjectiveMeasures) shows the Likert plots, or stacked percentage bar plots, alongside violin plots with the same non-parametric, ranked sum tests previously used. Participants preferred to use radial for this task. Participants were also more confident of their answers and found radial tours easier to use compared with the grand tour. All factors have reportedly low familiarity something we expect from crowdsourced participants.

```{r figSubjectiveMeasures, out.width="100%", fig.show='asis', fig.cap='The subjective measures of the 84 responses of the post-study survey, 5 discrete Likert scale levels of aggrement. (L) Likert plots (stacked percent bar plots) with (R) violin plots of the same measures. Violin plots are overlaid with global significance from the Kruskal-Wallis test, and pairwise significance from the Wilcoxon test, both are non-parametric, ranked sum tests.'}
if(F)
  browseURL("https://bookdown.org/Rmadillo/likert/is-there-a-significant-difference.html#permutation-mann-whitney-tests")

if(F) ## Creation and saving figure at:
  file.edit("./paper/R/fig_population_demographics.r")
knitr::include_graphics("./figures/figSubjectiveMeasures_w.violin_hori.pdf")
## Alternatively use:
# figSubjectiveMeasures_vert.pdf
# figSubjectiveMeasures_hori.pdf
# figSubjectiveMeasures_w.violin_vert.pdf
# figSubjectiveMeasures_w.violin_hori.pdf
```


# Conclusion {#sec:conclusion}

Above we conducted a with-in participant user study comparing the efficacy of 3 linear projection techniques. The participants performed a supervised cluster task, specifically the identification of which variables contribute to the separation between 2 target clusters. In summary, we that use of the radial tours increases accuracy while the use of the grand tour decreases the time it takes to perform this task. These effects are large relative to the other block parameterizations, but smaller than the random effect of the participant. Radial tour was subjectively most preferred, leads to more confidence in answers, and is easier to use than alternatives.

There are a number of ways that this study could be extended. In addition to expanding the support of the block parameterizations, more interesting directions include: type of task, factors used, and experience level of the target population. It is difficult to achieve good coverage given the number of possible permutations. Be sure to step back and plan what the target support, visuals, and task are. Keep in mind the volume and quality of responses from participants especially when crowdsourcing. These planning steps are useful for navigating when the complexity of the application details.


# Accompanying tool: spinifex application {#sec:spinifex}

To accompany this study we have produced a more general use tool to perform such exploratory analysis of high dimensional data. The \proglang{R} package, \pkg{spinifex}, [@spyrison_spinifex_2020] contains a free, open-source \pkg{shiny} [@chang_shiny_2020] application. The application allows users to upload, process, and interactively explore their data. Users can quickly traverse global and local extrema and then explore the nearby space with the radial tour as similarly applied in the user study. Limited implementations of grand, little, and local tours are also made available. Data can be imported in .csv and .rda format, and projections or animations can be saved as .png, .gif, and .csv formats where applicable. Run the following \proglang{R} code for help getting started.

```{r getting_started, eval = F}
install.packages("spinifex", dependencies = TRUE)
spinifex::run_app("intro")
spinifex::run_app("primary")
```

# Acknowledgments {#sec:acknowledgments}

This research was supported by an Australian Government Research Training Program (RTP) Scholarship. This article was created in \proglang{R} [@r_core_team_r:_2020], using \pkg{knitr} [@stodden_knitr:_2014] and \pkg{rmarkdown} [@xie_r_2018]. Visuals were prepared with \pkg{spinifex}. All packages used are available from the Comprehensive \proglang{R} Archive Network (CRAN) at \url{https://CRAN.R-project.org/}. The source files for this article, application, data, and analysis can be found at [github.com/nspyrison/spinifex_study/](https://github.com/nspyrison/spinifex_study/). The source code for the \pkg{spinifex} package and accompanying shiny application can be found at [github.com/nspyrison/spinifex/](https://github.com/nspyrison/spinifex/).

# Bibliography {#sec:bib}

\newpage

<!-- # Supplemental material -->

<!-- Consider: -->
<!-- -residual plots -->
<!-- -extending models with survey data; Di tends away from this, as they are not parameterization, they are aspects of the participant not known a priori.  -->