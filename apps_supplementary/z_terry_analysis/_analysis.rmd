---
title: "Terry's data"
author: "Nick Spyrison"
date: "07/03/2021"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
editor_options: 
  chunk_output_type: console
---
```{r setup, include=FALSE}
library(tidyverse)
file_suffix <- "terry"
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
rel_path <- function(rel_path = "."){
  rel_dir  <- dirname(rstudioapi::getSourceEditorContext()$path)
  rel_path <- paste0(rel_dir, "/", rel_path)
  normalizePath(rel_path, winslash = "/")
}

## Read from gsheets API4 and save local
if(F){
  ## Hash id of the google sheet
  ss_id <- "1K9qkMVRkrNO0vufofQJKWIJUyTys_8uVtEBdJBL_DzU" 
  raw <- googlesheets4::read_sheet(ss_id, sheet = 1L)
  ## Remove dummy rows
  raw <- raw %>% filter(!is.na(plot_active), ## dummy rows
                        !is.na(participant_num)) ## 2 missing participant_nums?
  ## Format 
  raw$full_perm_num = unlist(as.integer(raw$full_perm_num))
  raw$prolific_id = unlist(as.character(raw$prolific_id))
   ## Not prolific_id, Must
  raw %>% filter(nchar(prolific_id) != 24L)
   ## Filter to Terry
  raw <- raw %>% filter(tolower(prolific_id) == "terry")
  saveRDS(raw, paste0("./apps_supplementary/z_terry_analysis/data/raw_"
                      , file_suffix, ".rds"))
}
## Load load and clean, save cleaned
if(F){
  raw <- readRDS(rel_path(paste0("data/raw_", file_suffix, ".rds")))
  ## Only plot_active rows 
  ## AND Only prolific_ids (rows where nchar(prolific_id) == 24 charcters long)
  dat_active <- raw %>% filter(plot_active == TRUE,
                        nchar(prolific_id) == 24L)
  source(file = rel_path("../../paper/R/clean_participant_data.r"),
         local = T, echo = F)
  ## pivot variables columns longer for task-grained aggregation.
  dat_longer <- dat_active %>% pivot_longer_resp_ans_tbl()
  ## Mean impute missing sec_to_resp
  .mean_diff <- mean(dat_longer$sec_on_pg, na.rm = TRUE) -
    mean(dat_longer$sec_to_resp, na.rm = TRUE)
  dat_longer <- dat_longer %>%
    mutate(sec_to_resp = dplyr::if_else(is.na(sec_to_resp), 
                                        sec_on_pg - .mean_diff, sec_to_resp))
  ## Aggregate to task grain.
  dat_task_agg <- aggregate_task_vars(dat_longer)
  ## Fix observeEvent() over count of radial input_inter. 
  dat_task_agg <- dat_task_agg %>% 
    dplyr::mutate(task_input_inter = dplyr::if_else(
      factor == "radial", task_input_inter -1L, task_input_inter))
  ## Save task aggregated data.
  saveRDS(dat_task_agg, rel_path(paste0("data/dat_task_agg_", file_suffix, ".rds")))
}
## load aggregated data.
dat_task_agg <- readRDS(rel_path(paste0("data/dat_task_agg_", file_suffix, ".rds")))

## Local functions -----
## For labeling n, mean on boxplots, following:
#### https://medium.com/@gscheithauer/how-to-add-number-of-observations-to-a-ggplot2-boxplot-b22710f7ef80
## TODO: Has issue with non offseting the dodged colors.
stat_box_data <- function(y, lower_bound = min(-1, .data$.x_col) * 1.15) {
  data.frame(
    y = 0.95 * lower_bound,
    label = paste('n =', length(y), '\n',
                  'mean =', round(mean(y), 1), '\n')
  )
}
# ggplot(iris, aes(Species, Sepal.Length)) + 
#   geom_boxplot() +
#   stat_summary(
#     fun.data = stat_box_data, 
#     geom = "text", 
#     hjust = 0.5,
#     vjust = 0.9
#   )
my_theme <- list(
  theme_minimal(),
  scale_color_brewer(palette = "Dark2"),
  scale_fill_brewer(palette = "Dark2"),
  geom_hline(yintercept = 0L)
)
my_ggplot <- function(.aes = aes(x = eval, y = task_marks,
                                 color = is_training, fill = is_training),
                      .title = "Default title",
                      .data = dat_qual)
{
  ggplot(.data, .aes) +
    labs(title = .title) +
    my_theme +
    geom_point(
      position = position_jitterdodge(jitter.width = .3, jitter.height = .05), alpha = .2) +
    geom_boxplot(position = "dodge", alpha = .4)
}
my_ggplot2 <- function(.x_col,
                       .y_col,
                       .data = dat_qual,
                       .title = "Default title",
                       .aes = aes(x = {{.x_col}}, y = {{.y_col}},
                                  color = is_training, fill = is_training))
{
  ggplot(.data, .aes) +
    labs(title = .title) +
    my_theme +
    geom_point(
      position = position_jitterdodge(jitter.width = .3, jitter.height = .05), alpha = .2) +
    geom_boxplot(position = "dodge", alpha = .4) #+
  # stat_summary(
  #     fun.data = stat_box_data, 
  #     geom = "text", 
  #     hjust = 0.5,
  #     vjust = 0.9
  #   )
}
```

______

## Quality of data

I am concerned about the quality of the data, given that so many people experienced network issues. Let's explore.

```{r}
lb <- quantile(dat_task_agg$max_sec_to_resp, probs = .25) ## bottom 25 %
ub <- quantile(dat_task_agg$max_sec_to_resp, probs = .98) ## top 2 %
ggplot() + 
  geom_density(aes(max_sec_to_resp, fill = ""), dat_task_agg, alpha = .5) +
  ggtitle("Seconds to respond density") +
  my_theme +
  lims(x = c(0, 100)) +
  geom_vline(xintercept = c(lb, ub), linetype = 2L) +
  geom_label(aes(x = c(lb + 12, ub - 12), y = c(.05, .05), 
                 label = c(".25 percentile", ".98 percentile"))) +
  annotate("rect", xmin = -Inf, xmax = lb, ymin = -Inf, ymax = Inf,
           alpha = 0.3, fill = "firebrick1") +
  annotate("rect", xmin = lb, xmax = ub, ymin = -Inf, ymax = Inf,
           alpha = 0.3, fill = "aquamarine") +
  annotate("rect", xmin = ub, xmax = Inf, ymin = -Inf, ymax = Inf,
           alpha = 0.3, fill = "firebrick1")

print("!! For the rest of the analysis we will be looking at this middle chunk of data!!")
dat_qual <- dat_task_agg %>% filter(max_sec_to_resp > lb, max_sec_to_resp < ub)


obs_frac <- round(100L * nrow(dat_qual) / nrow(dat_task_agg), 2)
paste0("Percent of original data in subset: ", obs_frac, "%")

#sub_lb <- dat_task_agg %>% filter(max_sec_to_resp > lb)
#nrow(sub_lb) / nrow(dat_task_agg) #technically bottom 28.35% atm

### only look at eval data for correlation.
# cor_all  <- round(cor(dat_task_agg$max_sec_to_resp, dat_task_agg$task_marks), 3L)
# cor_qual <- round(cor(dat_qual$max_sec_to_resp, dat_qual$task_marks), 3L)
# paste0("cor(max_sec ~ task_marks) (all): ", cor_all)
# paste0("cor(max_sec ~ task_marks) (remove bottom 25%, top .5%): ", cor_qual)

```

```{r}
ggplot(dat_qual) + my_theme +
  geom_point(aes(max_sec_to_resp, task_marks,
                 fill = is_training, color = is_training), alpha = .2) +
  geom_smooth(aes(max_sec_to_resp, task_marks,
                  fill = is_training, color = is_training)) +
  ggtitle("Performance by last response time",
          subtitle = "after about 25 seconds marks decrease (difficulty? low attention?)")
```


## Even-ness of evaluation

Let's look at the distribution of quality evaluations by full_perm_num.

```{r}
l_u_ids <- dat_qual$prolific_id %>% unique() %>% length() ## ~54
id_evals <- round(nrow(dat_qual) / 9, 1) ## 67.2

u_prolific_ids <- dat_qual$prolific_id %>% unique()
u_prolific_ids <- 
  u_prolific_ids[!u_prolific_ids %in% c(NULL, "NULL" ,"", "DVIA or numbat")] 
l_u_prolific_ids <- u_prolific_ids  %>% length() ## ~ 52
prolific_evals <- 
  round(nrow(dat_qual[dat_qual$prolific_id %in% u_prolific_ids, ]) / 9, 1)
paste0(l_u_prolific_ids, " unique prolific ids, with about ", prolific_evals, " evaluations within bounds.")

## perm_num_agg
perm_num_agg <- dat_qual %>% group_by(full_perm_num, is_training) %>%
  summarise(n = n(),
            even_studies = max(sum(is_training) / 3, sum(!is_training) / 6),
            cnt_prolific_id = length(unique(prolific_id))
  ) %>% ungroup() %>% 
  mutate(is_past_tgt = if_else(even_studies > 3, TRUE, FALSE))

nums_past_tgt <- perm_num_agg$full_perm_num[perm_num_agg$is_past_tgt] %>%
  as.integer() %>% unique() # c(6, 16, 18, 24, 25, 26, 28, 29) #atm

.mn_val <- mean(perm_num_agg$even_studies)
ggplot(perm_num_agg, aes(x = full_perm_num, y = even_studies, 
                         color = is_training, fill = is_training)) +
  labs(title = "Evaluations by permutaion", 
       subtitle = "Though not from so many participants") +
  my_theme + 
  geom_bar(stat = "identity", position = "dodge") + 
  geom_hline(yintercept = .mn_val, linetype = 3) +
  geom_hline(yintercept = 3, linetype = 2) + 
  geom_text(aes(x = 30, y = 3.2, label = "target"), color = "black") +
  geom_text(aes(x = 28, y = .mn_val + .2, label = "current mean"), color = "black")
```

```{r}
## prolific_id_agg
prolific_id_agg <- dat_qual %>% group_by(prolific_id , is_training) %>%
  summarise(n = n(),
            even_studies = max(sum(is_training) / 3, sum(!is_training) / 6),
            cnt_participant_num = length(unique(participant_num))
  ) %>% ungroup() 
prolific_id_agg <- prolific_id_agg[order(prolific_id_agg$even_studies, decreasing = T),]

ggplot(prolific_id_agg, aes(x = prolific_id, y = even_studies, 
                         color = is_training, fill = is_training)) +
  labs(title = "Evaluations by prolific_id") +
  my_theme + 
  geom_bar(stat = "identity", position = "dodge") + geom_hline(yintercept = 1) +
  geom_text(aes(x = .95 * max(length(unique(prolific_id_agg$prolific_id))), y = 1.2, 
                label = "ideal"), color = "black")

print("highest number of evals per person:")
head(prolific_id_agg)
```



## Marks by ... 

### Factor

```{r}
my_ggplot2(.x_col = factor, 
          .y_col = task_marks,
          .title = "Marks by factor")
```

### Evaluation order

```{r}
my_ggplot(.aes = aes(x = eval, y = task_marks,
                     color = is_training, fill = is_training),
          .title = "Marks by evaluation order",
          .data = dat_qual)
```

### Within-participants Evaluation order

```{r}
## Create a global unique id (guid), doesn't fix the issue, because the double counted t3 was from repeat 1_1 runs, on mar 4, remove it.

## instead we'll apply a simple filter
dat_qual_wi_participant <- dat_qual %>%
  filter(task_marks > -1L, task_marks < 1L) %>% 
  mutate(frame_pro_id = as.integer(prolific_id))
# g <- 
  ggplot(dat_qual_wi_participant, 
            aes(x = eval, y = task_marks,
                frame = frame_pro_id,
                group = frame_pro_id,
                color = is_training, fill = is_training)
  ) +
  labs(title = "Within Participants, Marks by evaluation order") +
  #theme_bw() +
  geom_point(
    aes(size = max_sec_to_resp), alpha = .2,
    position = position_jitterdodge(jitter.width = .8,
                                    jitter.height = .05)
  ) +
  geom_line(alpha = .2)
# plotly::ggplotly(g)
# #R> Error in -data$group : invalid argument to unary operator

## using jitter, in geom_lines doesn't perform the same offset as geom_point.

cor_sec_to_resp <- cor(dat_qual_wi_participant$max_sec_to_resp,
                       dat_qual_wi_participant$task_marks) %>% round(3)
cor_eval <- cor(as.integer(dat_qual_wi_participant$eval),
                dat_qual_wi_participant$task_marks) %>% round(3)
cor_cnt_resp <- cor(dat_qual_wi_participant$cnt_resp, 
                    dat_qual_wi_participant$task_marks) %>% round(3)

print(paste0(
  "Quite busy, looking at the correlation, cor(eval number, marks) = ", cor_eval,
  ", a moderate negative value given that, cor(max time to respond, marks) = ", 
  cor_sec_to_resp
))

print("Tried animating over participants, but erroring (Error in -data$group : invalid argument to unary operator) on a valid ggplot. Would be across the board with such low correlation")


## Reviewing correlations, nothing too exciting, 
# skimr::skim(dat_qual)
# corr_dat <- dat_qual %>% 
#   mutate(eval = as.numeric(eval)) %>% 
#   select(-z_weight_check)
# num_col_ind <- unlist(lapply(corr_dat, is.numeric))  
# car_dat_mat <- corr_dat[, num_col_ind] %>% as.matrix() %>% cor()
# col3 <- colorRampPalette(c("blue", "white", "red")) 
# corrplot::corrplot.mixed(car_dat_mat, 
#                          lower.col = col3(100),
#                          upper.col = col3(100))
```

### Covariance

```{r} 
my_ggplot(aes(x = vc, y = task_marks,
              color = is_training, fill = is_training),
          "Marks by var-covariance",
          .data = dat_qual)
```

### Dimension

```{r}
my_ggplot(aes(x = p_dim, y = task_marks,
              color = is_training, fill = is_training),
          "Marks by dimension",
          .data = dat_qual)
```

### Location

```{r}
my_ggplot(aes(x = location, y = task_marks,
              color = is_training, fill = is_training),
          "Marks by location",
          .data = dat_qual)
```

#### Facet by factor

```{r}
my_ggplot(aes(x = location, y = task_marks,
              color = is_training, fill = is_training),
          "Marks by location, faceted by factor",
          .data = dat_qual) + facet_wrap(vars(factor))
```

#### Facet by covariance shape

```{r}
my_ggplot(aes(x = location, y = task_marks,
              color = is_training, fill = is_training),
          "Marks by location, faceted by covariance shape",
          .data = dat_qual) + 
  facet_wrap(vars(vc))
```

#### Facet by evaluation order

```{r}
my_ggplot(aes(x = location, y = task_marks,
              color = is_training, fill = is_training),
          "Marks by location, faceted by evaluation order",
          .data = dat_qual) + 
  facet_wrap(vars(eval))
```

______

## Speed by factor, order

```{r}
my_ggplot(aes(x = factor, y = max_sec_to_resp,
              color = is_training, fill = is_training),
          "Seconds till last response by factor",
          .data = dat_qual) +
  coord_cartesian(ylim = c(0L, 70L))

my_ggplot(aes(x = eval, y = max_sec_to_resp,
              color = is_training, fill = is_training),
          "Seconds till last response by evaluation order",
          .data = dat_qual) +
  coord_cartesian(ylim = c(0L, 70L))
```

______

## Input and response interactions

```{r}
my_ggplot(aes(x = factor, y = task_input_inter,
              color = is_training, fill = is_training),
          "Number of input interaction (throughness) by factor",
          .data = dat_qual) +
  coord_cartesian(ylim = c(0L, 30L))

my_ggplot(aes(x = factor, y = task_resp_inter,
              color = is_training, fill = is_training),
          "Number of response interaction (inverse confidence) by factor",
          .data = dat_qual)
```



