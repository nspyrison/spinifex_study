---
title: "prolifico 100"
author: "Nick Spyrison"
date: "11/03/2021"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
header-includes:
   - \usepackage{amsmath}
   - \usepackage{showframe}
editor_options:
  chunk_output_type: console
---
```{r setup, include=FALSE}
require("tidyverse")
require("dplyr")
require("ggpubr") ## for tests on the plot
require("cowplot") ## for aggregating plots
require("lme4") ## Random Effects (RE) model creation
require("merTools")
require("performance") ## tidy model eval

knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
rel_path <- function(rel_path = "."){
  rel_dir  <- dirname(rstudioapi::getSourceEditorContext()$path)
  rel_path <- paste0(rel_dir, "/", rel_path)
  normalizePath(rel_path, winslash = "/")
}
```


```{r LOAD_FORMAT_LOCAL_FUNCS}
## Read from gsheets API4 and save local
if(F){
  ## Hash id of the google sheet
  ss_id <- "1K9qkMVRkrNO0vufofQJKWIJUyTys_8uVtEBdJBL_DzU" 
  raw <- googlesheets4::read_sheet(ss_id, sheet = 1)
  ## Remove dummy rows
  raw <- raw %>% filter(!is.na(plot_active))
  
  ## Format, unlist not needed lately
  # raw$full_perm_num = unlist(as.integer(raw$full_perm_num))
  # raw$prolific_id = unlist(as.character(raw$prolific_id))
  
  dim(raw)
  saveRDS(raw, "./apps_supplementary/v4_prolifico_100/data/raw_prolific_100.rds")
}
## Load load and clean, save cleaned
if(F){
  raw <- readRDS(rel_path("data/raw_prolific_100.rds"))
  ## Only plot_active rows 
  ## AND Only participants (rows where nchar(participant) == 24 charcters long)
  dat_active <- raw %>% filter(nchar(stringr::str_trim(prolific_id)) == 24) ## trimmed nchar(prolifico_id) = 24L
  source(file = rel_path("../../paper/R/clean_participant_data.r"),
         local = TRUE, echo = FALSE)
  ## pivot variables columns longer for task-grained aggregation.
  dat_longer <- dat_active %>% pivot_longer_resp_ans_tbl()
  ## Impute missing sec_to_resp, via mean diff with sec_on_pg
  .mean_diff <- mean(dat_longer$sec_on_pg, na.rm = TRUE) -
    mean(dat_longer$sec_to_resp, na.rm = TRUE)
  dat_longer <- dat_longer %>%
    mutate(sec_to_resp =
             if_else(is.na(sec_to_resp), sec_on_pg - .mean_diff, sec_to_resp))
  ## Aggregate to task grain.
  dat_task_agg <- aggregate_task_vars(dat_longer)
  ## Fix observeEvent() over count of radial input_inter.
  dat_task_agg <- dat_task_agg %>%
    mutate(task_input_inter =
             if_else(factor == "radial", task_input_inter -1, task_input_inter))
  ## Plot friendly titles
  dat_task_agg <- dat_task_agg %>%
    mutate(prolific_id = stringr::str_trim(prolific_id), 
           instance_id = paste(sep = "_", participant_num, full_perm_num, prolific_id)) %>%
    rename(simulation = sim_nm, shape = vc, dim = p_dim, order = eval, participant = prolific_id,
           `is training` = is_training, `# response interactions` = task_resp_inter,
           `seconds to last response` = sec_to_resp, `seconds on page` = sec_on_pg,
           `# of responses` = cnt_resp, marks = task_marks,
           `parameter permutation` = full_perm_num)
  ## Save task aggregated data.
  saveRDS(dat_task_agg, rel_path("data/dat_task_agg_prolific_100.rds"))
}
## load aggregated data.
dat_task_agg <- readRDS(rel_path("data/dat_task_agg_prolific_100.rds"))
## filter out raining data for now; is even eval is the new color/fill go to.
dat_task_agg <- dat_task_agg %>% filter(`is training` == FALSE)


## Local functions -----
## For labeling n, mean on boxplots, following:
#### https://medium.com/@gscheithauer/how-to-add-number-of-observations-to-a-ggplot2-boxplot-b22710f7ef80

## direct ggplot2 helpers
my_theme <- list(
  theme_bw(),
  scale_color_brewer(palette = "Dark2"),
  scale_fill_brewer(palette = "Dark2"),
  geom_hline(yintercept = 0L),
  theme(legend.position = "bottom",
        legend.box = "vertical",
        legend.margin = margin(-6))
)

## indirect (via ggpubr/cowplot) ggplot2 helpers
my_ggpubr <- function(df, x = "factor", y = "marks", title = "Title missing", subtitle = waiver()){
  ## Find height of global significance test text.
  .x_lvls <- df %>% pull({{x}}) %>% levels()
  .y_range <- diff(range(df[y]))
  .n_lvls <- length(.x_lvls)
  .lab.y <- (.05 * .y_range) * (1 + .n_lvls) * .y_range + max(df[y])
  my_comparisons <- list(c("pca", "grand"), 
                         c("grand", "radial"), 
                         c("pca", "radial"))

  ## Plot
  ggviolin(df, x = x, y = y, fill = x, alpha = .6,
           palette = "Dark2", shape = x,
           add = c("mean"), ## Black circle, can change size, but not shape or alpha?
           draw_quantiles = c(.25, .5, .75)) +
    stat_compare_means(method = "wilcox.test", 
                       comparisons = my_comparisons, 
                       label = "p.signif") + ## pairwise test
    # stat_compare_means(label = "p.signif", label.y = .lab.y - .4,
    #                    method = "wilcox.test", ref.group = .x_lvls[1]) + ## Test each lvl w.r.t. first level.
    stat_compare_means( ## Global test
                       label.y = .lab.y,
                       aes(label = paste0("Krusal-p=", ..p.format..))
                       ) + ## custom label
    my_theme +
    ggtitle(title, subtitle)
}
my_ggpubr_facet <- function(..., facet = "location"){
  facet(my_ggpubr(...), facet.by = facet)
}
```

______

# Results

## Even-ness of evaluation

Let's look at the distribution of quality evaluations by full_perm_num.

```{r}
#### Aggregation tables

## instance_agg
instance_agg <- dat_task_agg %>%
  group_by(instance_id, participant_num, `parameter permutation`, participant) %>%
  summarise(`n instance evals` = n() / 6) %>%
  ungroup() %>%
  mutate(is_instance_even = if_else(`n instance evals` == 1, TRUE, FALSE)) %>%
  arrange(desc(`n instance evals`))
## Find vector of evenly evaled instance_ids
instance_id_is_even_whitelist <- instance_agg %>%
  filter(is_instance_even == TRUE) %>%
  pull(instance_id)
## Decode the original dataset by evenness of instance_id.
dat_qual <- dat_task_agg %>%
  mutate(`is even instance` =
           if_else(instance_id %in% instance_id_is_even_whitelist, TRUE, FALSE))
  
## participant aggregate table
participant_agg <- dat_qual %>%
  group_by(participant, `is even instance`) %>%
  summarise(`even evaluations` = n() / 6) %>%
  ungroup() %>%
  arrange(desc(`even evaluations`))
## perm_num aggregate table
perm_num_agg <- dat_qual %>%
  group_by(`parameter permutation`, `is even instance`) %>%
  summarise(`even evaluations` = n() / 6) %>%
  ungroup() %>%
  arrange(desc(`even evaluations`))

#### Identify and remove instances with over evaled perms AND participants.
## Identify participants that have performed more than 1 even eval from
participant_blacklist <- participant_agg %>%
  group_by(participant) %>%
  summarise(`even evaluations` = sum(`even evaluations`)) %>%
  ungroup() %>%
  filter(`even evaluations` > 1) %>%
  pull(participant)
## Identify over evaled perm numbers
perm_num_blacklist <- perm_num_agg %>%
  filter(`is even instance` == TRUE,
         `even evaluations` > 3) %>%
  pull(`parameter permutation`)
## instance_id's in all surveys
survey_wider <- readRDS(rel_path("../survey/survey_wider.rds"))
instance_id_in_survey <- unique(survey_wider$instance_id)

## Decode the original dataset by evenness of instance_id.
dat_qual <- dat_qual %>%
  mutate(is_particiapnat_blacklisted =
           if_else(participant %in% participant_blacklist, TRUE, FALSE),
         is_perm_num_blacklisted =
           if_else(`parameter permutation` %in% perm_num_blacklist, TRUE, FALSE),
         is_instance_id_in_survey =
           if_else(instance_id %in% instance_id_in_survey, TRUE, FALSE),
         removal_priority = if_else(is_instance_id_in_survey == TRUE, -1L,
           is_particiapnat_blacklisted + is_perm_num_blacklisted),
         perm_prolific_id = paste(sep = "_", `parameter permutation`, participant))

## Identify the final results to keep as prioritized with the first 3 evals of:
#### arrange(`parameter permutation`, removal_priority, desc(write_dt))
#### where removal_priority get 1 each for perm and participant being over evaled.
instance_id_whitelist <- dat_qual %>%
  filter(`is even instance` == TRUE) %>%
  arrange(`parameter permutation`, removal_priority, desc(write_dt)) %>%
  group_by(`parameter permutation`, instance_id) %>%
  summarise(`even evaluations` = 1) %>%
  mutate(wi_perm_instance_rn = row_number()) %>%
  filter(wi_perm_instance_rn < 4) %>%
  pull(instance_id)
 
## Apply the final white list, the last 3 even evaluations of each perm
dat_qual <- dat_qual %>%
  filter(instance_id %in% instance_id_whitelist)
if(interactive() == TRUE)
  saveRDS(dat_qual, "./apps_supplementary/v4_prolifico_100/data/dat_qual.rds")

N <- length(unique(dat_qual$instance_id))
print(paste0("N = ", N, " unique instance_id."))

#### Plot Evenness:
## Evaluations by participant
# ggplot(participant_agg, aes(x = participant, y = `even evaluations`,
#                             color = `is even instance`, fill = `is even instance`)) +
#   labs(title = "Evaluations by participant") +
#   my_theme +
#   geom_bar(stat = "identity", position = "dodge") + geom_hline(yintercept = 1) +
#   geom_text(aes(x = .95 * max(length(unique(participant))), y = 1.2,
#                 label = "ideal"), color = "black")

## Evaluations by parameter permutation
.mn_val <- sum(perm_num_agg$`even evaluations`[perm_num_agg$`is even instance` == TRUE], na.rm = TRUE) / 36
# (gg_eval_by_perm_num <- perm_num_agg %>%
#     ggplot(aes(x = `parameter permutation`, y = `even evaluations`,
#                color = `is even instance`, fill = `is even instance`)) +
#   labs(title = "Evaluations by parameter permutaion") +
#   my_theme + 
#   geom_bar(stat = "identity", position = "dodge") +
#   geom_hline(yintercept = .mn_val, linetype = 2) +
#   geom_hline(yintercept = 3, linetype = 1) +
#   geom_text(aes(x = 33, y = 3.2, label = "target"), color = "black") +
#   geom_text(aes(x = 26, y = .mn_val + .2, label = "mean of even evaluations"), color = "black")
# )

## Evaluation by parameter permutations with candidates removed
print("After evaluating the evenness of participants, permutations, the probability of adverse network interactions we have selected 3 evaluations of each block permutation to perfom the analysis on:")
print("Note: Training removed, partial evaluations removed, only the evaluations of the remaining instances.")

#### Now update perm agg and plot
perm_num_agg2 <- dat_qual %>%
  group_by(`parameter permutation`, `is even instance`) %>%
  summarise(`even evaluations` = n() / 6) %>%
  ungroup()

(gg_eval_by_perm_num_removed <- perm_num_agg2 %>%
    ggplot(aes(x = `parameter permutation`, y = `even evaluations`,
               color = `is even instance`, fill = `is even instance`)) +
  labs(title = "Evaluations by parameter permutaion", 
       subtitle = "Remaining set of data, 3 evaluations of all block parameter permutations") +
  my_theme +
  geom_bar(stat = "identity", position = "dodge") +
  geom_hline(yintercept = 3, linetype = 2) +
  geom_text(aes(x = 33, y = 3.1, label = "target"), color = "black")
)
```


## Mixed regression

_Context: 108 evals; use block parameters to predict marks_

<!-- 1) Eval parameters -->
\begin{align*}
\text{base model:}&&    \widehat{\textbf{Y}} =& \textbf{Z} \* \mu + \textbf{X} \* \beta + \epsilon \\
\textbf{Terms:}&&    \textbf{Expanded Model:~~} & \\
\alpha&&    \widehat{marks} =& \textbf{Z} \* \mu + \alpha_i + \epsilon \\
\alpha + \beta&&    \widehat{marks} =& \textbf{Z} \* \mu + \alpha_i + \beta_j + \epsilon \\
\alpha + \gamma&&    \widehat{marks} =& \textbf{Z} \* \mu + \alpha_i + \gamma_k + \epsilon \\
\alpha + \delta&&    \widehat{marks} =& \textbf{Z} \* \mu + \alpha_i + \delta_l + \epsilon \\
\alpha + \zeta&&    \widehat{marks} =& \textbf{Z} \* \mu + \alpha_i + \zeta_m + \epsilon \\
\end{align*}

where

\begin{align*}
&\mu \text{ is the intercept of the model} \\
&\epsilon \sim \mathcal{N}(0,~\sigma), the error of the model \\
&\textbf{Z} \sim \mathcal{N}(0,~\tau), \text{ the random effect of participant} \\
&\alpha_i \text{, fixed term for factor}~|~i\in (\text{pca, grand, radial}) \\
&\beta_j \text{, fixed term for location}~|~j\in (\text{0_1, 33_66, 50_50}) \text{ percent noise mixing of a noise and signal variable respectively} \\
&\gamma_k \text{, fixed term for shape}~|~k\in (\text{EEE, EEV, EVV banana}) \text{ mclust model family shapes described above} \\
&\delta_l \text{, fixed term for dim}~|~dim\in (\text{4 variables with 3 cluster, 6 variables with 4 clusters}) \\
\end{align*}


```{r}
## Mixed (fixed and random/variable) effects regression model
### following along with:
if(F) 
  browseURL("https://m-clark.github.io/mixed-models-with-R/random_intercepts.html#running-a-mixed-model")

## Print coef of the model that are greater than selected t_val
mod_coef_gt_t <- function(mod, gt_t = 1.5){
  .coef <- summary(mod)$coefficients %>% data.frame() ## tibble failed
  .coef %>% filter(abs(t.value) > gt_t)
}
mod_anova_gt_f <- function(mod, gt_f = 1){
  .anova <- anova(mod) %>% data.frame() ## tibble failed
  .anova %>% filter(abs(F.value) > gt_f)
}

## The Models:
a <- lmer(marks ~ factor + (1 | participant), data = dat_qual)
ab <- lmer(marks ~ factor + location + (1 | participant), data = dat_qual)
ac <- lmer(marks ~ factor + shape + (1 | participant), data = dat_qual)
ad <- lmer(marks ~ factor + dim + (1 | participant), data = dat_qual)
abc <- lmer(marks ~ factor + location + shape + (1 | participant), data = dat_qual)
abd <- lmer(marks ~ factor + location + dim + (1 | participant), data = dat_qual)
acd <- lmer(marks ~ factor + shape + dim + (1 | participant), data = dat_qual)
abcd <- lmer(marks ~ factor + location + shape + dim + (1 | participant), data = dat_qual)
AB <- lmer(marks ~ factor * location + (1 | participant), data = dat_qual)
AC <- lmer(marks ~ factor * shape + (1 | participant), data = dat_qual)
AD <- lmer(marks ~ factor * dim + (1 | participant), data = dat_qual)
ABC <- lmer(marks ~ factor * location * shape + (1 | participant), data = dat_qual)
ABD <- lmer(marks ~ factor * location * dim + (1 | participant), data = dat_qual)
ACD <- lmer(marks ~ factor * shape * dim + (1 | participant), data = dat_qual)
ABCD <- lmer(marks ~ factor * location * shape * dim + (1 | participant), data = dat_qual)

model_ls <- list(`alpha` = a,
                 `alpha + beta` = ab,
                 `alpha + gamma` = ac,
                 `alpha + delta` = ad,
                 `alpha + beta + gamma` = abc, 
                 `alpha + beta + delta` = abd,
                 `alpha + gamma + delta` = acd,
                 `alpha + beta + gamma + delta` = abcd,
                 `alpha * beta` = AB,
                 `alpha * gamma` = AC,
                 `alpha * delta` = AD,
                 `alpha * beta * gamma` = ABC, 
                 `alpha * beta * delta` = ABD,
                 `alpha * gamma * delta` = ACD,
                 `alpha * beta * gamma * delta` = ABCD)

# mod_anova_gt_f(ABCD, gt_f = 2)
#ABCD_f.gt2 <- lmer(marks ~ factor * location * shape * dim + (1 | participant), data = dat_qual)
# z <- lmer(marks ~ factor * location * shape * dim + (1 | participant), data = dat_qual)
# drop1(z)


## Local functions to abstract code complexity
## A residual plot with marginal density, ggplot2 obj
plot_residual <- function(model){
  .df <- data.frame(predicted  = predict(model),
                    residual = residuals(model),
                    factor = dat_qual$factor)
  p <- ggplot(.df, aes(x = predicted, y = residual, color = factor, shape = factor)) +
    geom_point(alpha = .33) + my_theme + ggtitle("Residual plot") +
    theme(legend.position = "bottom",
          legend.box = "vertical",
          legend.margin = margin(-6))
  p <- ggExtra::ggMarginal(p, type = "density", fill = "grey80")
  return(p)
}

## A qq plot of the Random Effect simulation
plot_REsim_qq <- function(model){
  .df <- data.frame(y = REsim(model)$mean)
  ggplot(.df, aes(sample = y)) +
    stat_qq(alpha = .5) + stat_qq_line() + my_theme +
    ggtitle("qq plot of the mean of random effects simulation")
}
## Adds kable markup to bold the max/min of a column.
format_column_extrema <- function(df, col, extrema = max, markup = "*"){
  ## c("*", "**", "~~"), c("italics", "bold", "strikethrough")
  v <- as.data.frame(df[, col])[, 1]
  ## Make sure values are not factors
  r_idx <- which(v == extrema(v))
  ## Update formatting
  v[r_idx] <- paste0(markup, v[r_idx], markup)
  df[, col] <- v
  return(df)
}

## lapply over models
performance_ls <- aic_ls <- bic_ls <- summary_ls <- plotREsim_ls <-
  plot_REsim_qq_ls <- plot_residual_ls <- annova_ls <- list()
factors_vec <- fixef_vec <- vector()
mute <- lapply(seq_along(model_ls), function(i){
  this_model <- model_ls[[i]]
  performance_ls[[i]] <<- performance::model_performance(this_model)
  factors_vec[i] <<- ncol(attr(terms(this_model), "factors"))
  fixef_vec[i] <<- length(fixef(this_model))
  ## Other model artifacts
  # summary_ls[[i]] <<- summary(this_model)
  # plotREsim_ls[[i]] <<- plotREsim(REsim(this_model))
  # plot_REsim_qq_ls[[i]] <<- plot_REsim_qq(this_model)
  # plot_residual_ls[[i]] <<- plot_residual(this_model)
  # annova_ls[[i]] <<- anova(this_model)
})
.perf_df <- dplyr::bind_rows(performance_ls)
.model_comp_colnms <- c("Fixed effects", "No. levels", "No. terms", "AIC", 
                        "BIC", "R2 cond. (on RE)", "R2 marg. (w/o RE)", "RMSE",
                        "AIC / R2 marg.")
model_comp_tbl <- tibble(names(model_ls),
                         factors_vec,
                         fixef_vec,
                         round(.perf_df[, 1]),
                         round(.perf_df[, 2]),
                         round(.perf_df[, 3], 3),
                         round(.perf_df[, 4], 3),
                         round(.perf_df[, 6], 3),
                         round(.perf_df[, 3], 3) / round(.perf_df[, 4], 3))
colnames(model_comp_tbl) <- .model_comp_colnms

## Latex formatting
model_comp_tbl <- model_comp_tbl %>%
  format_column_extrema(4, min) %>%
  format_column_extrema(5, min) %>%
  format_column_extrema(6, max) %>%
  format_column_extrema(7, max) %>%
  format_column_extrema(8, min)

model_comp_tbl <- model_comp_tbl[c(1, 12, 15), 1:8]

## print table
knitr::kable(model_comp_tbl)
#`Model name`                   | Terms
#1 alpha                        | Factor
#2 alpha * beta * gamma         | Factor * Location * Shape
#3 alpha * beta * gamma * delta | Factor * Location * Shape * Dim
ABC_re_parti_sim <- lmer(marks ~ factor * location * shape + (1 | participant) 
                          + (1 | simulation), data = dat_qual)
print("MODEL: ABC + re(participant + simulation)")
ggEffectRanges <- plotREsim(REsim(ABC_re_parti_sim)) +
  ggtitle("Effect range vs mean marks for participants and simulations", "Effect range for the model alpha * beta * gamma") +
  theme(axis.title.x = element_blank()) +
  ylab("effect range (CI of Gelman sim)")

  if(F)
    browseURL("http://www.cookbook-r.com/Manipulating_data/Summarizing_data/")
## Summarizes data.
## Gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95%).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   groupvars: a vector containing names of columns that contain grouping variables
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {

  require(plyr)
  
  # New version of length which can handle NA's: if na.rm==T, don't count them
  length2 <- function (x, na.rm=FALSE) {
    if (na.rm) sum(!is.na(x))
    else       length(x)
  }
  
  # This does the summary. For each group's data frame, return a vector with
  # N, mean, and sd
  datac <- ddply(data, groupvars, .drop=.drop,
                 .fun = function(xx, col) {
                   c(N    = length2(xx[[col]], na.rm=na.rm),
                     mean = mean   (xx[[col]], na.rm=na.rm),
                     sd   = sd     (xx[[col]], na.rm=na.rm)
                   )
                 },
                 measurevar
  )
  
  # Rename the "mean" column    
  datac <- rename(datac, c("mean" = measurevar))
  
  datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
  
  # Confidence interval multiplier for standard error
  # Calculate t-statistic for confidence interval: 
  # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
  ciMult <- qt(conf.interval/2 + .5, datac$N-1)
  datac$ci <- datac$se * ciMult
  
  return(datac)
}

#### If you eant to show boxplots cannot aggregate over evaluation, 
## By participant
participant_agg <- summarySE(dat_qual, "marks", "participant") %>% 
  mutate(participant = forcats::fct_reorder(participant, marks))
ggParticipantRanges <- ggplot(participant_agg) +
  geom_point(aes(participant, marks), alpha = .2, size = 2) +
  geom_linerange(aes(participant, ymin = marks - ci, ymax = marks + ci), alpha = .3) +
  my_theme +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  coord_cartesian(ylim = c(-.75, .75)) +
  xlab("participant (n=6 every line)") +
  ylab("CI mean marks (alpha=.95)")
ggParticipantRanges <- ggExtra::ggMarginal(ggParticipantRanges, 
                                           type = "density", fill = "grey80")
## By simulation
simulation_agg <- summarySE(dat_qual, "marks", "simulation") %>% 
  mutate(simulation = forcats::fct_reorder(simulation, marks))
ggSimulationRanges <- ggplot(simulation_agg) +
  geom_point(aes(simulation, marks), alpha = .2, size = 2) +
  geom_linerange(aes(simulation, ymin = marks - ci, ymax = marks + ci), alpha = .3) +
  my_theme + 
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title.y = element_blank()) +
  coord_cartesian(ylim = c(-.75, .75)) +
  xlab("simulation (n=36 every line)")
ggSimulationRanges <-
  ggExtra::ggMarginal(ggSimulationRanges, 
                      type = "density", fill = "grey80")
botRanges <-
  cowplot::plot_grid(ggParticipantRanges, ggSimulationRanges,
                     ncol = 2, rel_widths = c(1.07, 1))
(figEffectRange <- cowplot::plot_grid(ggEffectRanges, botRanges, nrow = 2))
```

## Violin plot of models

### Model alpha

```{r}
(marks_by_factor <-
   my_ggpubr(dat_qual,
             x = "factor", y = "marks",
             title = "Marks by factor"))
```

### Model alpha * beta * gamma

```{r}
(marks_by_factor_facet_location_shape <-
   my_ggpubr_facet(dat_qual,
                   x = "factor", y = "marks",
                   title = "Marks by factor, faceting on location and shape",
                   subtitle = "The fixed terms of model alpha * beta * gamma",
                   facet = c("location", "shape")))
```

<!-- ### Model alpha * beta * gamma * delta -->

<!-- ```{r} -->
<!-- (marks_by_factor_facet_location_shape) -->
<!-- (marks_by_factor_facet_location_dim <- -->
<!--     my_ggpubr_facet(dat_qual, -->
<!--                     x = "factor", y = "marks", -->
<!--                     title = "Marks by factor, faceting on location and dim", -->
<!--                     facet = c("location", "dim"))) -->
<!-- (marks_by_factor_facet_shape_dim <- -->
<!--     my_ggpubr_facet(dat_qual, -->
<!--                     x = "factor", y = "marks", -->
<!--                     title = "Marks by factor, faceting on location and dim", -->
<!--                     facet = c("shape", "dim"))) -->
<!-- ``` -->




# Supplemental material

## Last response time density

We are concerned about the quality of the data, given that so many people experienced network issues. Let's explore.

```{r}
.ann_offset <- 7
ggplot() +
  geom_density(aes(`seconds to last response`, fill = ""), dat_qual, alpha = .5) +
  ggtitle("Seconds to respond density") +
  my_theme +
  lims(x = c(0, 100)) +
  geom_vline(xintercept = 60, linetype = 3L) +
  geom_label(aes(x =  60 - .ann_offset, y = .03, label = "plot turns off"))
```

```{r}
marks_by_last_resp <- ggplot(dat_qual) + my_theme +
  geom_point(aes(`seconds to last response`, marks,
                 fill = factor, color = factor), alpha = .2) +
  geom_smooth(aes(`seconds to last response`, marks,
                  fill = factor, color = factor)) +
  ggtitle("Mark by last response time with marginal density")

(marks_by_last_resp <- ggExtra::ggMarginal(marks_by_last_resp, type = "density",
                                           groupColour = TRUE, groupFill = TRUE))
```


### Regressing against the time

_#TODO: XXX continue rework here_

Because factor uniquely performed so well, let's use it as a benchmark as compared to models:

- marks ~ factor + RE_participant -- benchmark
- marks ~ factor + RE_participant.data
- time ~ factor + RE_participant
- time ~ factor + RE_participant.data

```{r}
marks_f_re_partcipant <- lmer(marks ~ factor + (1 | participant), data = dat_qual) ## Benchmark
marks_f_re_partcipant.data <-
  lmer(marks ~ factor + (1 | participant) + (1 | simulation), data = dat_qual)
time_f_re_partcipant <-
  lmer(`seconds to last response` ~ factor + (1 | participant), data = dat_qual)
time_f_re_partcipant.data <-
  lmer(`seconds to last response` ~ factor + (1 | participant) + (1 | simulation), data = dat_qual)

model_ls3 <- list(`marks~F+RE(parti.)` = marks_f_re_partcipant,
                  `marks~F+RE(parti.+sim)` = marks_f_re_partcipant.data,
                  `time~F+RE(parti.)` = time_f_re_partcipant,
                  `time~F+RE(parti.+sim)` = time_f_re_partcipant.data
)

performance_ls3 <- list()
factors_vec3 <- fixef_vec3 <- vector()
mute <- lapply(seq_along(model_ls3), function(i){
  this_model <- model_ls3[[i]]
  performance_ls3[[i]] <<- performance::model_performance(this_model)
  factors_vec3[i] <<- ncol(attr(terms(this_model), "factors"))
  fixef_vec3[i] <<- length(fixef(this_model))
})

.perf_df3 <- dplyr::bind_rows(performance_ls3)
model_comp_tbl3 <- tibble(names(model_ls3),
                          factors_vec3,
                          fixef_vec3,
                          round(.perf_df3[, 1]),
                          round(.perf_df3[, 2]),
                          round(.perf_df3[, 3], 2),
                          round(.perf_df3[, 4], 2),
                          round(.perf_df3[, 6], 2))
colnames(model_comp_tbl3) <- .model_comp_colnms

knitr::kable(model_comp_tbl)
knitr::kable(model_comp_tbl3)

print("Random effect of the dataset as compared to that of the participant:")
summary(marks_f_re_partcipant.data)
.resim <- REsim(marks_f_re_partcipant.data)
plotREsim(.resim)
.resim_data <- .resim %>%
  filter(groupFctr == "simulation") %>%
  arrange(mean)
print("Most difficult and easiest datasets:")
head(.resim_data)
tail(.resim_data)
```

______

## Saving paper figures
```{r}
if(F){
  ## instance_id whitelist, the people kept for analysis. 
  #### (instance_id is: participant_num "_" perm_num "_" prolific_id)
  saveRDS(instance_id_whitelist,
          file = "./apps_supplementary/v4_prolifico_100/instance_id_whitelist.rds")
  
  ## Portrait dim, inside margin
  .u = "in"
  .w = 6.25
  .h = 9
  
  ## RE Effect ranges by mark quantiles
  ggsave("figEffectRange.png", plot = figEffectRange, path = "./paper/figures",
         device = "png", width = .w, height = .w, unit = .u)
  
  ## Marks by violin of factor faceting on location and shape
  ggsave("figMarksFactorLoctionShape.png", marks_by_factor_facet_location_shape,
         device = "png", width = .w, height = .w, unit = .u)
  
}
```


## Saving supplemental material figures

```{r}
if(F){
  ### dat_qual now saved inline with if(interactive()) ###
  .remove_y <- theme(axis.title.y = element_blank(),
                     axis.text.y = element_blank(),
                     axis.ticks.y = element_blank())
  .no_legend <- 
    list(theme(legend.position = "off",
               axis.text.x = element_text(angle = 30, vjust = 1, hjust = 1)),
         ggtitle(NULL))
  gc()
  (MargEval_notitle <- 
      cowplot::plot_grid(marks_by_factor + .no_legend + ggtitle(NULL),
                         marks_by_order + .remove_y + .no_legend,
                         marks_by_dim + .remove_y + .no_legend,
                         marks_by_shape + .remove_y + .no_legend,
                         ## marks_by_dim + .remove_y + .no_legend, # p only .6.
                         ncol = 4, rel_widths = c(3, 7, 1, 3)+5))
  title1 <- cowplot::ggdraw() +
    cowplot::draw_label("Marks by marginal block parameter",
                        x = .15, y = .6, hjust = .1, vjust = .5)
  gc()
  
  ## Marginal survey data
  (MargSurvey_notitle <-
      cowplot::plot_grid(marks_by_task_understanding + .no_legend + ggtitle(waiver()),
                         marks_by_age + .remove_y + .no_legend,
                         marks_by_data_viz_exp + .remove_y + .no_legend,
                         marks_by_education + .remove_y + .no_legend,
                         ncol = 4, rel_widths = c(7, 6, 6, 5)))
  title2 <- cowplot::ggdraw() +
    cowplot::draw_label("Marks by marginal survey variable",
                        x = .15, y = .6, hjust = .1, vjust = .5)
  gc()
  (figMarksByMarg <-
      cowplot::plot_grid(title1, MargEval_notitle, title2, MargSurvey_notitle,
                         nrow = 4, rel_heights = c(0.1, 1, .1, 1)))
  gc()
  ggsave("figMarksByMarg.png", plot = figMarksByMarg, path = "./paper/figures",
         device = "png", width = .w, height = .h * .8, unit = .u)
  
  ## Model tables
  warning("OLD NAMES")
  model_comp_tbl_ls <- list(models_eval = model_comp_tbl, 
                            models_survey = model_comp_tbl2, 
                            ext_models_eval.survey = model_comp_tbl3)
  saveRDS(model_comp_tbl_ls,
          file = "./paper/figures/model_comp_tbl_ls.rds")
  
  ## _Save model figure
  resim <- plotREsim(REsim(ABCD))
  resid <- plot_residual(marks_f_re_partcipant.data)
  figModel_notitle <- cowplot::plot_grid(resid, resim, ncol = 2, rel_widths = c(3, 5))
  title <- cowplot::ggdraw() +
    cowplot::draw_label("marks^ = factor + effect(participant) + effect(simulation)",
                        x = .5, y = .75, hjust = .5, vjust = 1)
  (figModel <- cowplot::plot_grid(title, figModel_notitle,
                                  ncol = 1, rel_heights = c(0.1, 1)))
  ggsave("figModels.png", plot = figModel, path = "./paper/figures",
         device = "png", width = 8, height = 4, unit = "in")
}
```