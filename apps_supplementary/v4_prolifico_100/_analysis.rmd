---
title: "prolifico 100"
author: "Nick Spyrison"
date: "11/03/2021"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
header-includes:
   - \usepackage{amsmath}
   - \usepackage{showframe}
editor_options: 
  chunk_output_type: console
---
```{r setup, include=FALSE}
library(tidyverse)
library("lme4")
library("merTools")

knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
rel_path <- function(rel_path = "."){
  rel_dir  <- dirname(rstudioapi::getSourceEditorContext()$path)
  rel_path <- paste0(rel_dir, "/", rel_path)
  normalizePath(rel_path, winslash = "/")
}

## Read from gsheets API4 and save local
if(F){
  ## Hash id of the google sheet
  ss_id <- "1K9qkMVRkrNO0vufofQJKWIJUyTys_8uVtEBdJBL_DzU" 
  raw <- googlesheets4::read_sheet(ss_id, sheet = 1L)
  ## Remove dummy rows
  raw <- raw %>% filter(!is.na(plot_active), ## dummy rows
                        !is.na(participant_num)) ## 2 missing participant_nums?
  ## Format 
  raw$full_perm_num = unlist(as.integer(raw$full_perm_num))
  raw$participant = unlist(as.character(raw$participant))
  dim(raw)
  saveRDS(raw, "./apps_supplementary/v4_prolifico_100/data/raw_prolific_100.rds")
}
## Load load and clean, save cleaned
if(F){
  raw <- readRDS(rel_path("data/raw_prolific_100.rds"))
  ## Only plot_active rows 
  ## AND Only participants (rows where nchar(participant) == 24 charcters long)
  dat_active <- raw %>% filter(plot_active == TRUE,
                               nchar(prolific_id) == 24L)
  source(file = rel_path("../../paper/R/clean_participant_data.r"),
         local = TRUE, echo = FALSE)
  ## pivot variables columns longer for task-grained aggregation.
  dat_longer <- dat_active %>% pivot_longer_resp_ans_tbl()
  ## Impute missing sec_to_resp, via mean diff with sec_on_pg
  .mean_diff <- mean(dat_longer$sec_on_pg, na.rm = TRUE) -
    mean(dat_longer$sec_to_resp, na.rm = TRUE)
  dat_longer <- dat_longer %>%
    mutate(sec_to_resp = dplyr::if_else(is.na(sec_to_resp), 
                                        sec_on_pg - .mean_diff, sec_to_resp))
  ## Aggregate to task grain.
  dat_task_agg <- aggregate_task_vars(dat_longer)
  ## Fix observeEvent() over count of radial input_inter. 
  dat_task_agg <- dat_task_agg %>% 
    dplyr::mutate(task_input_inter = dplyr::if_else(
      factor == "radial", task_input_inter -1L, task_input_inter))
  ## Plot friendly titles
  dat_task_agg <- dat_task_agg %>%
  mutate(instance_id = paste(sep = "_", participant_num, full_perm_num, prolific_id)) %>%
  rename(shape = vc, dim = p_dim, `evaluation order` = eval, participant = prolific_id,
         `is training` = is_training, `# response interactions` = task_resp_inter,
         `max seconds to respond` = max_sec_to_resp, `seconds on page` = max_sec_on_pg,
         `# of responses` = cnt_resp, marks = task_marks,
         `parameter permutation` = full_perm_num)
  ## Save task aggregated data.
  saveRDS(dat_task_agg, rel_path("data/dat_task_agg_prolific_100.rds"))
}
## load aggregated data.
dat_task_agg <- readRDS(rel_path("data/dat_task_agg_prolific_100.rds"))


## Local functions -----
## For labeling n, mean on boxplots, following:
#### https://medium.com/@gscheithauer/how-to-add-number-of-observations-to-a-ggplot2-boxplot-b22710f7ef80
my_theme <- list(
  theme_minimal(),
  scale_color_brewer(palette = "Dark2"),
  scale_fill_brewer(palette = "Dark2"),
  geom_hline(yintercept = 0L),
  theme(legend.position = "bottom",
        legend.box = "vertical",
        legend.margin = margin(-6))
)
my_ggplot <- function(.aes = aes(x = `evaluation order`, y = marks,
                                 color = `is training`, fill = `is training`),
                      .title = "Default title",
                      .data = dat_qual)
{
  ggplot(.data, .aes) +
    labs(title = .title) +
    my_theme +
    geom_point(
      position = position_jitterdodge(jitter.width = .3, jitter.height = .05), alpha = .2) +
    geom_boxplot(position = "dodge", alpha = .4)
}
```

______


## Even-ness of evaluation

Let's look at the distribution of quality evaluations by full_perm_num.

```{r}
#### Aggregation tables

## app_instance_agg
app_intance_agg <- dat_task_agg %>% filter(`is training` == FALSE) %>%
  group_by(instance_id, participant_num, `parameter permutation`, participant) %>%
  summarise(`n instance evals` = n()) %>% 
  ungroup() %>% 
  mutate(is_instance_even = if_else(`n instance evals` == 6, TRUE, FALSE)) %>% 
  arrange(desc(`n instance evals`))
## Find vector of evenly evaled instance_ids
even_evaled_instance_ids <- app_intance_agg %>%
  filter(is_instance_even == TRUE) %>%
  pull(instance_id)
## Decode the original dataset by evenness of instance_id.
dat_qual_full <- dat_task_agg %>% mutate(
  `is even instance` = if_else(instance_id %in% even_evaled_instance_ids, TRUE, FALSE))
dat_qual <- dat_qual_full %>% filter(`is training` == FALSE)

## participant_agg
participant_agg <- dat_qual %>%
  group_by(participant, `is even instance`) %>%
  summarise(`even evaluations` = n() / 6) %>%
  ungroup() %>%
  arrange(desc(`even evaluations`))

## perm_num_agg
perm_num_agg <- dat_qual %>%
  group_by(`parameter permutation`, `is even instance`) %>%
  summarise(`even evaluations` = n() / 6) %>%
  ungroup() %>%
  arrange(desc(`even evaluations`))

#### Plot Evenness:

## Evaluations by participant
ggplot(participant_agg, aes(x = participant, y = `even evaluations`,
                            color = `is even instance`, fill = `is even instance`)) +
  labs(title = "Evaluations by participant") +
  my_theme + 
  geom_bar(stat = "identity", position = "dodge") + geom_hline(yintercept = 1) +
  geom_text(aes(x = .95 * max(length(unique(participant))), y = 1.2,
                label = "ideal"), color = "black")

## Evaluations by parameter permutation
.mn_val <- sum(perm_num_agg$`even evaluations`[perm_num_agg$`is even instance` == TRUE], na.rm = TRUE) / 36
(gg_eval_by_perm_num <- perm_num_agg %>% 
    ggplot(aes(x = `parameter permutation`, y = `even evaluations`,
               color = `is even instance`, fill = `is even instance`)) +
  labs(title = "Evaluations by parameter permutaion") +
  my_theme + 
  geom_bar(stat = "identity", position = "dodge") + 
  geom_hline(yintercept = .mn_val, linetype = 3) +
  geom_hline(yintercept = 3, linetype = 2) + 
  geom_text(aes(x = 33, y = 3.2, label = "target"), color = "black") +
  geom_text(aes(x = 26, y = .mn_val + .2, label = "mean of full evaluations"), color = "black")
)

##TODO: RESUME CHECKING HERE, Something feels off. mean looks low, review 24-29 for example.
##Participant_number isn't matching with key, will need to evaluate.
```



## Last response time density

I am concerned about the quality of the data, given that so many people experienced network issues. Let's explore.

```{r}
print(paste0("N_raw = ", length(unique(dat_qual$participant)), " unique prolific ids"))
lb <- quantile(dat_qual$`max seconds to respond`, probs = .25) ## bottom 25 %
ub <- quantile(dat_qual$`max seconds to respond`, probs = .95) ## top 5 %
ann_offset <- 7
ggplot() + 
  geom_density(aes(`max seconds to respond`, fill = ""), dat_qual, alpha = .5) +
  ggtitle("Seconds to respond density") +
  my_theme +
  lims(x = c(0, 100)) +
  # geom_vline(xintercept = c(lb, ub), linetype = 2L) +
  geom_vline(xintercept = 60, linetype = 3L) +
  geom_label(aes(x =  60 - ann_offset, #c(lb + ann_offset, 60 - ann_offset, ub - ann_offset), 
                 y = .03, #c(.05, .045, .05), 
                 label = "plot turns off"#c("25th percentile", "plot turns off" ,"95th percentile")
  )) #+
  # annotate("rect", xmin = -Inf, xmax = lb, ymin = -Inf, ymax = Inf,
  #          alpha = 0.3, fill = "firebrick1") +
  # annotate("rect", xmin = lb, xmax = ub, ymin = -Inf, ymax = Inf,
  #          alpha = 0.3, fill = "aquamarine") +
  # annotate("rect", xmin = ub, xmax = Inf, ymin = -Inf, ymax = Inf,
  #          alpha = 0.3, fill = "firebrick1")

# dat_qual <- dat_qual
#%>% filter(`max seconds to respond` > lb, `max seconds to respond` < ub)
## windsorized conflicts with the within participant evaluation.

#print(paste0("N_windsorized = ", length(unique(dat_qual$participant)), " unique prolific ids"))
# obs_percent <- round(100L * nrow(dat_qual) / nrow(dat_task_agg), 2)
# paste0("Percent of original task evaluations in subset: ", obs_percent, "%")
# print("NOTE: The rest of the analysis we will be looking at this middle ~70% of the evaluations.")
```

```{r}
ggplot(dat_qual) + my_theme +
  geom_point(aes(`max seconds to respond`, marks,
                 fill = `is training`, color = `is training`), alpha = .2) +
  geom_smooth(aes(`max seconds to respond`, marks,
                  fill = `is training`, color = `is training`)) +
  ggtitle("Mark by last response time")
```


## Within-participants -- Marks by Evaluation order

```{r}
  ggplot(dat_qual, 
            aes(x = factor, y = marks,
                
                color = `is training`, fill = `is training`)
  ) +
  geom_boxplot(alpha = .05) +
  labs(title = "Within Participants, Marks by factor") +
  scale_color_brewer(palette = "Dark2") + 
  scale_fill_brewer(palette = "Dark2") +
  geom_line(aes(frame = participant, group = participant),
            alpha = .2)

# cor_sec_to_resp <- cor(dat_qual$`max seconds to respond`,
#                        dat_qual$marks) %>% round(3)
# cor_eval <- cor(as.integer(dat_qual$`evaluation order`),
#                 dat_qual$marks) %>% round(3)
# cor_cnt_resp <- cor(dat_qual$`seconds on page`, 
#                     dat_qual$marks) %>% round(3)
# 
# print(paste0(
#   "Quite busy, looking at the correlation, cor(evaluation order, marks) = ", cor_eval,
#   ", a moderate negative value given that, cor(max time to respond, marks) = ", 
#   cor_sec_to_resp
# ))




## Reviewing correlations, nothing too exciting, 
# corr_dat <- dat_qual %>%
#   mutate(`evaluation order` = as.numeric(`evaluation order`)) %>% 
#   dplyr::select(!z_weight_check)
# num_col_ind <- unlist(lapply(corr_dat, is.numeric))
# car_dat_mat <- corr_dat[, num_col_ind] %>% as.matrix() %>% cor()
# col3 <- colorRampPalette(c("blue", "white", "red"))
# corrplot::corrplot.mixed(car_dat_mat,
#                          lower.col = col3(100),
#                          upper.col = col3(100))
```


## Random effects regression model 

We create a number of base models for comparison We have:

$$
\begin{align*}
\text{model F: } ~~~~~ \widehat{marks}_{partcipant~n} = 
  ~ &\beta_{0} + \Sigma_{f = 1}^3(\alpha_{factor~f} * \beta_{factor~f}) + 
  \Sigma_{n = 1}^N(effect_{participant~n}) + \epsilon \\
\text{model L: } ~~~~~ \widehat{marks}_{partcipant~n =
  ~ &\beta_{0} + \Sigma_{l = 1}^3(\alpha_{location~l} * \beta_{location~l}) +
  \Sigma_{n = 1}^N(effect_{participant~n}) + \epsilon \\
\text{model S: } ~~~~~ \widehat{marks}_{partcipant~n =
  ~ &\beta_{0} + \Sigma_{s = 1}^3(\alpha_{shape~s} * \beta_{shape~s}) +
  \Sigma_{n = 1}^N(effect_{participant~n}) + \epsilon \\
\text{model D: } ~~~~~ \widehat{marks}_{partcipant~n =
  ~ &\beta_{0} + \Sigma_{d = 1}^2(\alpha_{dim~d} * \beta_{dim~d}) +
  \Sigma_{n = 1}^N(effect_{participant~n}) + \epsilon \\
  
  \text{model FL: } ~~~~~ \widehat{marks}_{partcipant~n = ~ &\beta_{0} +
  \Sigma_{f = 1}^3\Sigma_{l = 1}^3(\alpha_{factor~f*location~l} * \beta_{factor~f*location~l}) + \\
  &\Sigma_{n = 1}^N(effect_{participant~n}) + \epsilon \\

\text{model FL+S+D: } ~~~~~ \widehat{marks}_{partcipant~n = ~ &\beta_{0} +
  \Sigma_{f = 1}^3\Sigma_{l = 1}^3(\alpha_{factor~f*location~l} * \beta_{factor~f*location~l}) + \\
  &\Sigma_{s = 1}^3(\alpha_{shape~s} * \beta_{shape~s}) +
  \Sigma_{d = 1}^2(\alpha_{dim~d} * \beta_{dim~d}) + \\
  &\Sigma_{n = 1}^N(effect_{participant~n}) + \epsilon \\
\end{align*}
$$

Where, 
$$\epsilon \sim \mathcal{N}(0,~\sigma) \\
effect_{participant~n} \sim \mathcal{N}(0,~\tau_{participant~n}) ~|~ n \in (1,~...,~N)  \\
factor_f \in (pca,~grand,~radial) \\
location_l \in (0/100,~33/66,~50/50) \text{ % mixing of a noise and signal variable respectively} \\
shape_s \in (EEE,~EEV,~EVV~banana) \\
dim_d \in (4,~6) \text{ variables, with 3 & 4 clusters respectively} \\
$$

Building on this, we add in vectors of all of our fixed factor terms: method factor, data dimension, variance-covariance shape, signal mixing location. Add a factor interaction to the number of input interactions as it is it intrinsically different based on the factor. Lastly we add the random effect of the participants. This random term, $effect_{participant}$, accounts for the difference between participant, that is the each individuals ability/disposition to effect their task marks. Then our mixed model is: 

$$
\begin{align*}
\widehat{marks} = ~
&\beta_{int} +
\beta_{SecResp} * SecResp +
\beta_{SecPg} * SecPg + 
\beta_{RespInter} * RespInter + \\
&\beta_{CntResp} * CntResp + 
\boldsymbol{\beta}_{InputInter*Factor} * InputInter * I(\boldsymbol{Factor}) +
\boldsymbol{\beta}_{factor} * I(\boldsymbol{factor}) + \\
&\boldsymbol{\beta}_{dim} * I(\boldsymbol{dim}) + 
\boldsymbol{\beta}_{shape} * I(\boldsymbol{shape}) + 
\boldsymbol{\beta}_{location} * I(\boldsymbol{location}) + 
\boldsymbol{\beta}_{participant} * \boldsymbol{effect}_{participant} +
\epsilon
\end{align*}
$$
where,  




```{r}
## Mixed (fixed and random/variable) effects regression model,
### following along with:
if(F) 
  browseURL("https://m-clark.github.io/mixed-models-with-R/random_intercepts.html#running-a-mixed-model")
#install.packages("lme4")

## The Models:
lmer_factor <- lmer(marks ~ factor + (1 | participant), data = dat_qual)
lmer_location <- lmer(marks ~ location + (1 | participant), data = dat_qual)
lmer_shape <- lmer(marks ~ shape + (1 | participant), data = dat_qual)
lmer_dim <- lmer(marks ~ dim + (1 | participant), data = dat_qual)
lmer_factorLocation <- lmer(marks ~ factor * location + (1 | participant), data = dat_qual)
lmer_factorLocation.dim <- 
  lmer(marks ~ factor * location + dim + (1 | participant), data = dat_qual)


# print(paste0("Model 1) simple terms of all variables. 16 terms remain after dropping 4 due to rank deficiency, AIC = ", 
#              round(aic_1, 0), "."))

### 2) remove the least bang for buck, 3 variables that are highly correlated, lose .1% AIC
marks_lmer2 <- lmer( ## 13 terms remain after dropping 3 due to rank deficiency
  marks ~
    `max seconds to respond` + `# response interactions` + task_input_inter * factor + ## Numeric
    factor + dim + shape + location + `evaluation order` + ## Fixed factor random terms
    (1 | participant), ## Random effect
  data = dat_qual
)
# aic_2 <- AIC(marks_lmer2)
# print("Model 2) simplify by removing 2 of the most correlated (redundant explaintion) numeric variables. We gain ~.2% AIC to remove 2 terms relative to the first model.")

### 3) Try to mix all terms of the simple model with factor
# print("Model 3) we try to make an over complex model by starting with model 2, leave independant terms and introduce factor interactions. This costs 22 terms to improve AIC by 6.5%")
marks_lmer3 <- lmer( ## 35 terms remain after dropping 10 due to rank deficiency, 
  marks ~
    ## Independent
    `max seconds to respond` + `# response interactions` + task_input_inter + ## Numeric
    factor + dim * factor + shape + location + `evaluation order` + ## Fixed factor random terms
    (1 | participant) +
    ## factor interactions
    factor * (`max seconds to respond` + `seconds on page` + `# response interactions` + task_input_inter) + ## Numeric
    factor * (dim  + shape  + location + `evaluation order`) + ## Fixed factor random terms
    factor * (1 | participant), ## Random effect
  data = dat_qual
)
## Addition model warnings:
# Warning messages:
# 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
#   unable to evaluate scaled gradient
# 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
#   Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
aic_3 <- AIC(marks_lmer3)

# print("Confidence intervals:")
# confint(marks_lmer)
# 
# print("Head of participant effect:")
# coef(marks_lmer)$participant %>% head(5)
# 
# print("Prediction interval")
# predictInterval(marks_mixed_mod)   # for various model predictions, possibly with new data
# REsim(marks_mixed_mod)             # mean, median and sd of the random effect estimates

print("Let's take a closer look at model 2: \n summary:")
## Model summary
(s <- print(summary(marks_lmer2), digits = 3))

## Anova table
(a <- anova(marks_lmer2)) ## do we need t interact task_input_inter with factor (task_input_inter doesn't make sense for grand)?

## Residual plot
resid_2 <- data.frame(
  predicted  = predict(marks_lmer2), residual = residuals(marks_lmer2),
  factor = dat_qual$factor, 
  `# of responses` = dat_qual$`# of responses`,
  check.names = FALSE)
p <- ggplot(resid_2, aes(x = predicted, y = residual, color = factor, size = `# of responses`)) +
  geom_point(alpha = .2) + my_theme + ggtitle("Residuals by predcted values") + 
  theme(legend.position = "bottom",
        legend.box = "vertical",
        legend.margin = margin(-6))
(r <- ggExtra::ggMarginal(p, type = "density", fill = "grey80"))


## Random effects, as simulated from model posterior distributions
print("Random effect of participant, as simulated from the model posterior distributions")
(resim <- plotREsim(REsim(marks_lmer2)))  # plot the interval estimates
```


## Marks by ... 

### Factor

```{r}
(gg_marks_by_factor <- my_ggplot(
  .aes = aes(x = factor, y = marks,
             color = `is training`, fill = `is training`),
  .title = "Marks by factor",
  .data = dat_qual))
```

### Order, of evaluation

```{r}
(gg_marks_by_eval_order <- my_ggplot(.aes = aes(x = `evaluation order`, y = marks,
                     color = `is training`, fill = `is training`),
          .title = "Marks by evaluation order",
          .data = dat_qual))
```

### Shape, Variance-covariance 

```{r} 
(gg_marks_by_shape <- my_ggplot(aes(x = shape, y = marks,
              color = `is training`, fill = `is training`),
          "Marks by var-covariance",
          .data = dat_qual))
```

### Dimension

```{r}
(gg_marks_by_dim <- my_ggplot(aes(x = dim, y = marks,
              color = `is training`, fill = `is training`),
          "Marks by dimension",
          .data = dat_qual))
```

### Location, of signal mixing

```{r}
(gg_marks_by_location <- my_ggplot(aes(x = location, y = marks,
              color = `is training`, fill = `is training`),
          "Marks by location",
          .data = dat_qual))
```

#### Facet by factor

```{r}
my_ggplot(aes(x = location, y = marks,
              color = `is training`, fill = `is training`),
          "Marks by location, faceted by factor",
          .data = dat_qual) + facet_wrap(vars(factor))
```

#### Facet by covariance shape

```{r}
my_ggplot(aes(x = location, y = marks,
              color = `is training`, fill = `is training`),
          "Marks by location, faceted by covariance shape",
          .data = dat_qual) + 
  facet_wrap(vars(shape))
```

#### Facet by evaluation order

```{r}
my_ggplot(aes(x = location, y = marks,
              color = `is training`, fill = `is training`),
          "Marks by location, faceted by evaluation order",
          .data = dat_qual) + 
  facet_wrap(vars(`evaluation order`))
```

______

## Speed by factor, evaluation order

```{r}
my_ggplot(aes(x = factor, y = `max seconds to respond`,
              color = `is training`, fill = `is training`),
          "Seconds till last response by factor",
          .data = dat_qual) +
  coord_cartesian(ylim = c(0L, 70L))

my_ggplot(aes(x = `evaluation order`, y = `max seconds to respond`,
              color = `is training`, fill = `is training`),
          "Seconds till last response by evaluation order",
          .data = dat_qual) +
  coord_cartesian(ylim = c(0L, 70L))
```

______

## Input and response interactions

```{r}
my_ggplot(aes(x = factor, y = task_input_inter,
              color = `is training`, fill = `is training`),
          "Number of input interaction (throughness) by factor",
          .data = dat_qual) +
  coord_cartesian(ylim = c(0L, 30L))

my_ggplot(aes(x = factor, y = `# response interactions`,
              color = `is training`, fill = `is training`),
          "Number of response interaction (inverse confidence) by factor",
          .data = dat_qual)
```


## Manual saving
```{r}
if(F){
  
  gg_eval_by_perm_num ## evenness of perm num 
  gg_marks_by_factor
  gg_marks_by_eval_order
  gg_marks_by_shape
  gg_marks_by_dim
  gg_marks_by_location
  
  ## MODEL
  ## _Save model figures
  (figModel <- cowplot::plot_grid(r, resim, ncol = 2, rel_widths = c(3, 2)))
  ggsave("figModels.png", plot = figModel, path = "./paper/figures",
         device = "png", width = 8, height = 4, unit = "in")
  ## _Save model summary, annova, residual_df in as list.
  model_ls <- list(
    summary = s,
    anova = a,
    residual_df = resid_2
  )
  saveRDS(model_ls, file = "./paper/figures/model_ls.rds")
}

```