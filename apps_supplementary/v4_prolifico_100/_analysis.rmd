---
title: "prolifico 100"
author: "Nick Spyrison"
date: "11/03/2021"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
header-includes:
   - \usepackage{amsmath}
   - \usepackage{showframe}
editor_options:
  chunk_output_type: console
---
```{r setup, include=FALSE}
require(tidyverse)
require("ggpubr") ## for tests on the plot
require("cowplot") ## for aggregating plots
require("lme4") ## Random Effects (RE) model creation
require("merTools")
require("performance") ## tidy model eval

knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
rel_path <- function(rel_path = "."){
  rel_dir  <- dirname(rstudioapi::getSourceEditorContext()$path)
  rel_path <- paste0(rel_dir, "/", rel_path)
  normalizePath(rel_path, winslash = "/")
}
```


```{r}
## Read from gsheets API4 and save local
if(F){
  ## Hash id of the google sheet
  ss_id <- "1K9qkMVRkrNO0vufofQJKWIJUyTys_8uVtEBdJBL_DzU" 
  raw <- googlesheets4::read_sheet(ss_id, sheet = 1)
  ## Remove dummy rows
  raw <- raw %>% filter(!is.na(plot_active))
  
  ## Format, unlist not needed lately
  # raw$full_perm_num = unlist(as.integer(raw$full_perm_num))
  # raw$prolific_id = unlist(as.character(raw$prolific_id))
  
  dim(raw)
  saveRDS(raw, "./apps_supplementary/v4_prolifico_100/data/raw_prolific_100.rds")
}
## Load load and clean, save cleaned
if(F){
  raw <- readRDS(rel_path("data/raw_prolific_100.rds"))
  ## Only plot_active rows 
  ## AND Only participants (rows where nchar(participant) == 24 charcters long)
  dat_active <- raw %>% filter(nchar(stringr::str_trim(prolific_id)) == 24) ## trimmed nchar(prolifico_id) = 24L
  source(file = rel_path("../../paper/R/clean_participant_data.r"),
         local = TRUE, echo = FALSE)
  ## pivot variables columns longer for task-grained aggregation.
  dat_longer <- dat_active %>% pivot_longer_resp_ans_tbl()
  ## Impute missing sec_to_resp, via mean diff with sec_on_pg
  .mean_diff <- mean(dat_longer$sec_on_pg, na.rm = TRUE) -
    mean(dat_longer$sec_to_resp, na.rm = TRUE)
  dat_longer <- dat_longer %>%
    mutate(sec_to_resp =
             if_else(is.na(sec_to_resp), sec_on_pg - .mean_diff, sec_to_resp))
  ## Aggregate to task grain.
  dat_task_agg <- aggregate_task_vars(dat_longer)
  ## Fix observeEvent() over count of radial input_inter.
  dat_task_agg <- dat_task_agg %>%
    mutate(task_input_inter =
             if_else(factor == "radial", task_input_inter -1, task_input_inter))
  ## Plot friendly titles
  dat_task_agg <- dat_task_agg %>%
    mutate(prolific_id = stringr::str_trim(prolific_id), 
           instance_id = paste(sep = "_", participant_num, full_perm_num, prolific_id)) %>%
    rename(simulation = sim_nm, shape = vc, dim = p_dim, order = eval, participant = prolific_id,
           `is training` = is_training, `# response interactions` = task_resp_inter,
           `seconds to last response` = sec_to_resp, `seconds on page` = sec_on_pg,
           `# of responses` = cnt_resp, marks = task_marks,
           `parameter permutation` = full_perm_num)
  ## Save task aggregated data.
  saveRDS(dat_task_agg, rel_path("data/dat_task_agg_prolific_100.rds"))
}
## load aggregated data.
dat_task_agg <- readRDS(rel_path("data/dat_task_agg_prolific_100.rds"))
## filter out raining data for now; is even eval is the new color/fill go to.
dat_task_agg <- dat_task_agg %>% filter(`is training` == FALSE)


## Local functions -----
## For labeling n, mean on boxplots, following:
#### https://medium.com/@gscheithauer/how-to-add-number-of-observations-to-a-ggplot2-boxplot-b22710f7ef80

## direct ggplot2 helpers
my_theme <- list(
  theme_bw(),
  scale_color_brewer(palette = "Dark2"),
  scale_fill_brewer(palette = "Dark2"),
  geom_hline(yintercept = 0L),
  theme(legend.position = "bottom",
        legend.box = "vertical",
        legend.margin = margin(-6))
)
## indirect (via ggpubr/cowplot) ggplot2 helpers
my_ggpubr <- function(df, x, y, title = "Title missing"){
  ## Create a list of comparison levels to test significance, all combinations.
  .fill_lvls <- df %>% pull({{x}}) %>% levels()
  .combn_mat <- t(combn(.fill_lvls, 2))
  .combn_mat_ord <- t(combn(1:length(.fill_lvls), 2))
  my_comparisons <- lapply(1:nrow(.combn_mat), FUN = function(i){
    c(.combn_mat[i, 1], .combn_mat[i, 2])
  })
  
  ### doesn;'t seem to give all lvls...
  # tgt_ord <- data.frame(.combn_mat_ord) %>% arrange(desc(X1), X2)
  # my_comparisons <- data.frame(NA)
  # for(i in 1:nrow(tgt_ord)){
  #   for(j in 1:ncol(tgt_ord)){
  #     my_comparisons[i, j] <- .fill_lvls[tgt_ord[i, j]]
  #   }
  # }
  ## Find height of global significance test text.
  .y_range <- diff(range(df[y]))
  .lab.y <- .05 * .y_range + max(df[y])
  ## Plot
  ggboxplot(df,  x = x, y = y, fill = x, alpha = .6,
            palette = "Dark2", shape = x,
            add = "jitter", add.params = list(color = x, alpha = .3, width = .2)) +
    #stat_compare_means(comparisons = my_comparisons, label = "p.format") +
    stat_compare_means(label.y = .lab.y) +
    my_theme +
    ggtitle(title)
}
my_ggpubr_facet <- function(df, x, y,
                            title = "Title missing", facet = "location"){
  ## Create a list of comparison levels to test significance, all combinations.
  .fill_lvls <- df %>% pull({{x}}) %>% levels()
  .combn_mat <- t(combn(.fill_lvls, 2))
  my_comparisons <- lapply(1:nrow(.combn_mat), FUN = function(i){
    c(.combn_mat[i, 1], .combn_mat[i, 2])
  })
  ## Find height of global significance test text.
  .y_range <- diff(range(df[y]))
  .lab.y <- .05 * .y_range + max(df[y])
  ## Plot
  p <- ggboxplot(df,  x = x, y = y, fill = x, alpha = .6,
                 palette = "Dark2", shape = x,
                 add = "jitter", add.params = list(color = x, alpha = .3, width = .2)) +
    #stat_compare_means(comparisons = my_comparisons, label = "p.format") +
    stat_compare_means(label.y = .lab.y) +
    my_theme +
    ggtitle(title)
  facet(p, facet.by = facet)
}
```

______


## Even-ness of evaluation

Let's look at the distribution of quality evaluations by full_perm_num.

```{r}
#### Aggregation tables

## instance_agg
instance_agg <- dat_task_agg %>%
  group_by(instance_id, participant_num, `parameter permutation`, participant) %>%
  summarise(`n instance evals` = n() / 6) %>%
  ungroup() %>%
  mutate(is_instance_even = if_else(`n instance evals` == 1, TRUE, FALSE)) %>%
  arrange(desc(`n instance evals`))
## Find vector of evenly evaled instance_ids
instance_id_is_even_whitelist <- instance_agg %>%
  filter(is_instance_even == TRUE) %>%
  pull(instance_id)
## Decode the original dataset by evenness of instance_id.
dat_qual <- dat_task_agg %>%
  mutate(`is even instance` =
           if_else(instance_id %in% instance_id_is_even_whitelist, TRUE, FALSE))
  
## participant aggregate table
participant_agg <- dat_qual %>%
  group_by(participant, `is even instance`) %>%
  summarise(`even evaluations` = n() / 6) %>%
  ungroup() %>%
  arrange(desc(`even evaluations`))
## perm_num aggregate table
perm_num_agg <- dat_qual %>%
  group_by(`parameter permutation`, `is even instance`) %>%
  summarise(`even evaluations` = n() / 6) %>%
  ungroup() %>%
  arrange(desc(`even evaluations`))

#### Identify and remove instances with over evaled perms AND participants.
## Identify participants that have performed more than 1 even eval from
participant_blacklist <- participant_agg %>%
  group_by(participant) %>%
  summarise(`even evaluations` = sum(`even evaluations`)) %>%
  ungroup() %>%
  filter(`even evaluations` > 1) %>%
  pull(participant)
## Identify over evaled perm numbers
perm_num_blacklist <- perm_num_agg %>%
  filter(`is even instance` == TRUE,
         `even evaluations` > 3) %>%
  pull(`parameter permutation`)
## instance_id's in all surveys
survey_wider <- readRDS(rel_path("../survey/survey_wider.rds"))
instance_id_in_survey <- unique(survey_wider$instance_id)

## Decode the original dataset by evenness of instance_id.
dat_qual <- dat_qual %>%
  mutate(is_particiapnat_blacklisted =
           if_else(participant %in% participant_blacklist, TRUE, FALSE),
         is_perm_num_blacklisted =
           if_else(`parameter permutation` %in% perm_num_blacklist, TRUE, FALSE),
         is_instance_id_in_survey =
           if_else(instance_id %in% instance_id_in_survey, TRUE, FALSE),
         removal_priority = if_else(is_instance_id_in_survey == TRUE, -1L,
           is_particiapnat_blacklisted + is_perm_num_blacklisted),
         perm_prolific_id = paste(sep = "_", `parameter permutation`, participant))

## Identify the final results to keep as prioritized with the first 3 evals of:
#### arrange(`parameter permutation`, removal_priority, desc(write_dt))
#### where removal_priority get 1 each for perm and participant being over evaled.
instance_id_whitelist <- dat_qual %>%
  filter(`is even instance` == TRUE) %>%
  arrange(`parameter permutation`, removal_priority, desc(write_dt)) %>%
  group_by(`parameter permutation`, instance_id) %>%
  summarise(`even evaluations` = 1) %>%
  mutate(wi_perm_instance_rn = row_number()) %>%
  filter(wi_perm_instance_rn < 4) %>%
  pull(instance_id)
 
## Apply the final white list, the last 3 even evaluations of each perm
dat_qual <- dat_qual %>%
  filter(instance_id %in% instance_id_whitelist)
if(interactive() == TRUE)
  saveRDS(dat_qual, "./apps_supplementary/v4_prolifico_100/data/dat_qual.rds")

N <- length(unique(dat_qual$instance_id))
print(paste0("N = ", N, " unique instance_id."))

#### Plot Evenness:
## Evaluations by participant
ggplot(participant_agg, aes(x = participant, y = `even evaluations`,
                            color = `is even instance`, fill = `is even instance`)) +
  labs(title = "Evaluations by participant") +
  my_theme +
  geom_bar(stat = "identity", position = "dodge") + geom_hline(yintercept = 1) +
  geom_text(aes(x = .95 * max(length(unique(participant))), y = 1.2,
                label = "ideal"), color = "black")

## Evaluations by parameter permutation
.mn_val <- sum(perm_num_agg$`even evaluations`[perm_num_agg$`is even instance` == TRUE], na.rm = TRUE) / 36
(gg_eval_by_perm_num <- perm_num_agg %>%
    ggplot(aes(x = `parameter permutation`, y = `even evaluations`,
               color = `is even instance`, fill = `is even instance`)) +
  labs(title = "Evaluations by parameter permutaion") +
  my_theme + 
  geom_bar(stat = "identity", position = "dodge") +
  geom_hline(yintercept = .mn_val, linetype = 2) +
  geom_hline(yintercept = 3, linetype = 1) +
  geom_text(aes(x = 33, y = 3.2, label = "target"), color = "black") +
  geom_text(aes(x = 26, y = .mn_val + .2, label = "mean of even evaluations"), color = "black")
)

## Evaluation by parameter permutations with candidates removed
print("After evaluating the evenness of participants, permutations, the probability of adverse network interactions we have selected 3 evaluations of each block permutation to perfom the analysis on:")
print("Note: Training removed, partial evaluations removed, only the evaluations of the remaining instances.")

#### Now update perm agg and plot
perm_num_agg2 <- dat_qual %>%
  group_by(`parameter permutation`, `is even instance`) %>%
  summarise(`even evaluations` = n() / 6) %>%
  ungroup()

(gg_eval_by_perm_num_removed <- perm_num_agg2 %>%
    ggplot(aes(x = `parameter permutation`, y = `even evaluations`,
               color = `is even instance`, fill = `is even instance`)) +
  labs(title = "Evaluations by parameter permutaion", 
       subtitle = "Remaining set of data, 3 evaluations of all block parameter permutations") +
  my_theme +
  geom_bar(stat = "identity", position = "dodge") +
  geom_hline(yintercept = 3, linetype = 2) +
  geom_text(aes(x = 33, y = 3.1, label = "target"), color = "black")
)
```

## Last response time density

We are concerned about the quality of the data, given that so many people experienced network issues. Let's explore.

```{r}
.ann_offset <- 7
ggplot() +
  geom_density(aes(`seconds to last response`, fill = ""), dat_qual, alpha = .5) +
  ggtitle("Seconds to respond density") +
  my_theme +
  lims(x = c(0, 100)) +
  geom_vline(xintercept = 60, linetype = 3L) +
  geom_label(aes(x =  60 - .ann_offset, y = .03, label = "plot turns off"))
```

```{r}
marks_by_last_resp <- ggplot(dat_qual) + my_theme +
  geom_point(aes(`seconds to last response`, marks,
                 fill = factor, color = factor), alpha = .2) +
  geom_smooth(aes(`seconds to last response`, marks,
                  fill = factor, color = factor)) +
  ggtitle("Mark by last response time with marginal density")

(marks_by_last_resp <- ggExtra::ggMarginal(marks_by_last_resp, type = "density",
                                           groupColour = TRUE, groupFill = TRUE))
```


## Within-participants -- Marks by Evaluation order

```{r}
ggplot(dat_qual, aes(x = factor, y = marks)) +
  geom_boxplot(alpha = .05) +
  labs(title = "Within Participants, Marks by factor") +
  scale_color_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2") +
  geom_line(aes(frame = participant, group = participant),
            alpha = .2)
```


## Random effects regression models

### Block paremeters 

We create a number of base models for comparison:

_Context: 108 evals; use block parameters to predict marks_

\begin{align*}
\text{model F: } ~~~~~ \widehat{marks}_{partcipant~n} = 
  ~ &\beta_{0} + \Sigma_{f = 1}^3(\alpha_{factor~f} * \beta_{factor~f}) + 
  effect_{participant~n} + \epsilon \\
\text{model L: } ~~~~~ \widehat{marks}_{partcipant~n} =
  ~ &\beta_{0} + \Sigma_{l = 1}^3(\alpha_{location~l} * \beta_{location~l}) +
  effect_{participant~n} + \epsilon \\
\text{model S: } ~~~~~ \widehat{marks}_{partcipant~n} =
  ~ &\beta_{0} + \Sigma_{s = 1}^3(\alpha_{shape~s} * \beta_{shape~s}) +
  effect_{participant~n} + \epsilon \\
\text{model D: } ~~~~~ \widehat{marks}_{partcipant~n} =
  ~ &\beta_{0} + \Sigma_{d = 1}^2(\alpha_{dim~d} * \beta_{dim~d}) +
  effect_{participant~n} + \epsilon \\
\text{model O: } ~~~~~ \widehat{marks}_{partcipant~n} =
  ~ &\beta_{0} + \Sigma_{o = 1}^6(\alpha_{order~o} * \beta_{order~o}) +
  effect_{participant~n} + \epsilon \\
  
\text{model FL: } ~~~~~ \widehat{marks}_{partcipant~n} = ~ &\beta_{0} +
  \Sigma_{f = 1}^3(\Sigma_{l = 1}^3(\alpha_{factor~f\*location~l} \* \beta_{factor~f*location~l})) + \\
  &effect_{participant~n} + \epsilon \\

\text{model F+L+S+D+O: } ~~~~~ \widehat{marks}_{partcipant~n} = ~ &\beta_{0} +
  \Sigma_{f = 1}^3(\alpha_{factor~f} \* \beta_{factor~f}) + 
  \Sigma_{l = 1}^3(\alpha_{location~l} \* \beta_{location~l}) + \\
  &\Sigma_{s = 1}^3(\alpha_{shape~s} \* \beta_{shape~s}) +
  \Sigma_{d = 1}^2(\alpha_{dim~d} \* \beta_{dim~d}) + \\
  &\Sigma_{o = 1}^6(\alpha_{order~o} \* \beta_{order~o}) + 
  effect_{participant~n} + \epsilon \\

\text{model F*L+S+D+O: } ~~~~~ \widehat{marks}_{partcipant~n} = ~ &\beta_{0} +
  \Sigma_{f = 1}^3(\Sigma_{l = 1}^3(\alpha_{factor~f\*location~l} * \beta_{factor~f\*location~l})) + \\
  &\Sigma_{s = 1}^3(\alpha_{shape~s} \* \beta_{shape~s}) +
  \Sigma_{d = 1}^2(\alpha_{dim~d} \* \beta_{dim~d}) + \\
  &\Sigma_{o = 1}^6(\alpha_{order~o} \* \beta_{order~o}) + 
  effect_{participant~n} + \epsilon \\

\text{model F*(L+S+D)+O: } ~~~~~ \widehat{marks}_{partcipant~n} = ~ &\beta_{0} +
  \Sigma_{f = 1}^3(\Sigma_{l = 1}^3(\alpha_{factor~f\*location~l} \* \beta_{factor~f\*location~l})) + \\
  &\Sigma_{f = 1}^3(\Sigma_{s = 1}^3(\alpha_{factor~f\*shape~s} \* \beta_{factor~f\*shape~s}) + \\
  &\Sigma_{d = 1}^2(\Sigma_{s = 1}^2(\alpha_{factor~f\*dim~d} \* \beta_{factor~f\*dim~d}) + \\
  &\Sigma_{o = 1}^6(\alpha_{order~o} \* \beta_{order~o}) + 
  effect_{participant~n} + \epsilon \\
\end{align*}


Where,

\begin{align*}
&\beta_0 \text{ is the sum of the marginal intercept and the mean of the participant effect} \\
&\epsilon \sim \mathcal{N}(0,~\sigma) \\
&effect_{participant~n} \sim \mathcal{N}(0,~\tau_{participant~n}) ~|~ n \in (1,~... ~N) \\
&factor~f \in (pca,~grand,~radial) \\
&location~l \in (0/100,~33/66,~50/50) \text{ percent mixing of a noise and signal variable respectively} \\
&shape~s \in (EEE,~EEV,~EVV~banana) \\
&dim~d \in (4,~6) \text{ variables with 3 \& 4 clusters respectively} \\
&order~o \in (1,~... ~6) \text{, treated as a factor variable rather than numeric variable}
\end{align*}



```{r}
## Mixed (fixed and random/variable) effects regression model
### following along with:
if(F) 
  browseURL("https://m-clark.github.io/mixed-models-with-R/random_intercepts.html#running-a-mixed-model")

## Print coef of the model that are greater than selected t_val
mod_coef_gt_t <- function(mod, gt_t = 1.5){
  coef <- summary(mod)$coefficients %>% data.frame() ## tibble failed
  coef %>% filter(abs(t.value) > gt_t)
}

## The Models:
m_factor <- lmer(marks ~ factor + (1 | participant), data = dat_qual)
m_location <- lmer(marks ~ location + (1 | participant), data = dat_qual)
m_shape <- lmer(marks ~ shape + (1 | participant), data = dat_qual)
m_dim <- lmer(marks ~ dim + (1 | participant), data = dat_qual)
m_order <- lmer(marks ~ order + (1 | participant), data = dat_qual)
m_param <- lmer(marks ~ `parameter permutation` + (1 | participant), data = dat_qual)
m_factorLocation <- 
  lmer(marks ~ factor * location + (1 | participant), data = dat_qual)
m_factor.location.shape.dim.order <- 
  lmer(marks ~ factor + location + shape + dim + order + (1 | participant), data = dat_qual)
m_factorLocation.shape.dim.order <- 
  lmer(marks ~ factor * location + shape + dim + order + (1 | participant), data = dat_qual)
m_factor_location.shape.dim_.order <- lmer(
  marks ~ factor * (shape + dim + location) + order + (1 | participant), data = dat_qual)

model_ls <- list(`F` = m_factor,
                 `L` = m_location,
                 `S` = m_shape,
                 `D` = m_dim,
                 `O` = m_order,
                 `F*L` = m_factorLocation,
                 `F+L+S+D+O` = m_factor.location.shape.dim.order,
                 `F*L+S+D+O` = m_factorLocation.shape.dim.order,
                 `F*(L+S+D)+O` = m_factor_location.shape.dim_.order)

## Local functions to abstract code complexity
## A residual plot with marginal density, ggplot2 obj
plot_residual <- function(model){
  .df <- data.frame(predicted  = predict(model),
                    residual = residuals(model),
                    factor = dat_qual$factor
  )
  p <- ggplot(.df, aes(x = predicted, y = residual, color = factor, shape = factor)) +
    geom_point(alpha = .33) + my_theme + ggtitle("Residual plot") +
    theme(legend.position = "bottom",
          legend.box = "vertical",
          legend.margin = margin(-6))
  p <- ggExtra::ggMarginal(p, type = "density", fill = "grey80")
  return(p)
}
plot_residual(m_factor_location.shape.dim_.order)
## A qq plot of the Random Effect simulation
plot_REsim_qq <- function(model){
  .df <- data.frame(y = REsim(model)$mean)
  ggplot(.df, aes(sample = y)) +
    stat_qq(alpha = .5) + stat_qq_line() + my_theme +
    ggtitle("qq plot of the mean of random effects simulation")
}
## Adds kable markup to bold the max/min of a column.
format_column_extrema <- function(df, col, extrema = max, markup = "**"){ 
  ## c("*", "**", "~~"), c("italics", "bold", "strikethrough")
  v <- as.data.frame(df[, col])[, 1]
  ## Make sure values are not factors
  r_idx <- which(v == extrema(v))
  ## Update formatting
  v[r_idx] <- paste0(markup, v[r_idx], markup)
  df[, col] <- v
  return(df)
}

## lapply over models
performance_ls <- aic_ls <- bic_ls <- summary_ls <- plotREsim_ls <-
  plot_REsim_qq_ls <- plot_residual_ls <- annova_ls <- list()
factors_vec <- fixef_vec <- vector()
mute <- lapply(seq_along(model_ls), function(i){
  this_model <- model_ls[[i]]
  performance_ls[[i]] <<- performance::model_performance(this_model)
  factors_vec[i] <<- ncol(attr(terms(this_model), "factors"))
  fixef_vec[i] <<- length(fixef(this_model))
  ## Other model artifacts
  # summary_ls[[i]] <<- summary(this_model)
  # plotREsim_ls[[i]] <<- plotREsim(REsim(this_model))
  # plot_REsim_qq_ls[[i]] <<- plot_REsim_qq(this_model)
  # plot_residual_ls[[i]] <<- plot_residual(this_model)
  # annova_ls[[i]] <<- anova(this_model)
})
.perf_df <- dplyr::bind_rows(performance_ls)
.model_comp_colnms <- c("Model name", "No. factors", "No. fixed effects", "AIC", 
                        "BIC", "R2 cond. (on RE)", "R2 marg. (w/o RE)", "RMSE")
model_comp_tbl <- tibble(names(model_ls),
                         factors_vec,
                         fixef_vec,
                         round(.perf_df[, 1]),
                         round(.perf_df[, 2]),
                         round(.perf_df[, 3], 3),
                         round(.perf_df[, 4], 3),
                         round(.perf_df[, 6], 3))
colnames(model_comp_tbl) <- .model_comp_colnms

## Latex formatting
model_comp_tbl <- model_comp_tbl %>%
  format_column_extrema(4, min) %>%
  format_column_extrema(5, min) %>%
  format_column_extrema(6, max) %>%
  format_column_extrema(7, max) %>%
  format_column_extrema(8, min)
```

### Parameters and survey

But, not only do we have the block parameterization, we also have post study-survey. Joining in the survey data we'll look at the 84 that also have survey data;

_Context: 84 evaluations + surveys; use block parameters, demographics, and expertise to predict marks_


```{r}
## Save dat_qual, the df for the remaining 108 instance_id's.
dat_qual <- readRDS(rel_path("data/dat_qual.rds"))
## Load aggregated survey data. filter to only surveys in the 108 instances in the analysis
survey_wider <- readRDS(rel_path("../survey/survey_wider.rds"))
instance_id_whitelist <- readRDS(rel_path("instance_id_whitelist.rds"))
## Only Prolific participants that were in the 108 instance_ids in the analysis
survey_wider <- survey_wider %>%
  filter(nchar(as.character(prolific_id)) == 24,
         instance_id %in% instance_id_whitelist)

print("Of the 84 that have filled out surveys, lets consider their evaluation data.")
eval_survey <- dplyr::right_join(dat_qual, survey_wider, by = "instance_id")
str(eval_survey)
paste0("Length of unique instance_id's: ", length(unique(eval_survey$instance_id)))
dim(eval_survey)

print("goal: we want to regress; testing if demographic or subjective experience is important")

f <- lmer(marks ~ factor + (1 | participant), data = eval_survey) ## Benchmark
f.parameters <- 
  lmer(marks ~ factor + location + shape + dim + order +
         (1 | participant), data = eval_survey)
f.survey <-
  lmer(marks ~ factor + pronoun + age + education + task_understanding +
         data_viz_exp + analysis_exp + (1 | participant), data = eval_survey)
f_parameters <-
  lmer(marks ~ factor * (location + shape + dim) + order +
         (1 | participant), data = eval_survey)
f_survey <-
 lmer(marks ~ factor * (pronoun + age + education + task_understanding +
         data_viz_exp + analysis_exp) + (1 | participant), data = eval_survey)
f.parameters.survey <-
  lmer(marks ~ factor + location + shape + dim + order + pronoun + age +
         education + task_understanding + data_viz_exp + analysis_exp +
         (1 | participant), data = eval_survey)
f_parameters_survey <-
  lmer(marks ~ factor * (location + shape + dim + order + pronoun + age +
         education + task_understanding + data_viz_exp + analysis_exp) +
         (1 | participant), data = eval_survey)
if(interactive())
  mod_coef_gt_t(f.parameters.survey, 1.5)
f.gt1.5 <-
  lmer(marks ~ factor + order + age + task_understanding + analysis_exp +
         (1 | participant), data = eval_survey)
if(interactive())
  mod_coef_gt_t(f_parameters_survey, 1.5)
f_gt1.5 <-
  lmer(marks ~ factor * (location + age + education + task_understanding +
                           data_viz_exp + analysis_exp) +
         (1 | participant), data = eval_survey)

### why is sim_
# .resim <- REsim(m_sub_gt2.re_sim)
# plotREsim(.resim)
# .resim %>%
#   filter(groupFctr == "simulation") %>%
#   arrange(mean)

model_ls2 <- list(`F` = f,
                  `F+parameters` = f.parameters,
                  `F+survey` = f.survey,
                  `F+parameters+survey` = f.parameters.survey,
                  `F*parameters` = f_parameters,
                  `F*survey` = f_survey,
                  `F*parameters*survey` = f_parameters_survey,
                  `F+:t_val>1.5` = f.gt1.5,
                  `F*:t_val>1.5` = f_gt1.5)

performance_ls2 <- list()
factors_vec2 <- fixef_vec2 <- vector()
mute <- lapply(seq_along(model_ls2), function(i){
  this_model <- model_ls2[[i]]
  performance_ls2[[i]] <<- performance::model_performance(this_model)
  factors_vec2[i] <<- ncol(attr(terms(this_model), "factors"))
  fixef_vec2[i] <<- length(fixef(this_model))
})

.perf_df2 <- dplyr::bind_rows(performance_ls2)
model_comp_tbl2 <- tibble(names(model_ls2),
                          factors_vec2,
                          fixef_vec2,
                          round(.perf_df2[, 1]),
                          round(.perf_df2[, 2]),
                          round(.perf_df2[, 3], 2),
                          round(.perf_df2[, 4], 2),
                          round(.perf_df2[, 6], 2))
colnames(model_comp_tbl2) <- .model_comp_colnms

## Latex formatting
model_comp_tbl2 <- model_comp_tbl2 %>%
  format_column_extrema(4, min) %>%
  format_column_extrema(5, min) %>%
  format_column_extrema(6, max) %>%
  format_column_extrema(7, max) %>%
  format_column_extrema(8, min)

## print tables
knitr::kable(model_comp_tbl)
knitr::kable(model_comp_tbl2)
```


### Regressing against the time

Because factor uniquely performed so well, let's use it as a benchmark as compared to models:

- marks ~ factor + RE_participant -- benchmark
- marks ~ factor + RE_participant.data
- time ~ factor + RE_participant
- time ~ factor + RE_participant.data

```{r}
marks_f_re_partcipant <- lmer(marks ~ factor + (1 | participant), data = dat_qual) ## Benchmark
marks_f_re_partcipant.data <-
  lmer(marks ~ factor + (1 | participant) + (1 | simulation), data = dat_qual)
time_f_re_partcipant <-
  lmer(`seconds to last response` ~ factor + (1 | participant), data = dat_qual)
time_f_re_partcipant.data <-
  lmer(`seconds to last response` ~ factor + (1 | participant) + (1 | simulation), data = dat_qual)

model_ls3 <- list(`marks~F+RE(parti.)` = marks_f_re_partcipant,
                  `marks~F+RE(parti.+sim)` = marks_f_re_partcipant.data,
                  `time~F+RE(parti.)` = time_f_re_partcipant,
                  `time~F+RE(parti.+sim)` = time_f_re_partcipant.data
)

performance_ls3 <- list()
factors_vec3 <- fixef_vec3 <- vector()
mute <- lapply(seq_along(model_ls3), function(i){
  this_model <- model_ls3[[i]]
  performance_ls3[[i]] <<- performance::model_performance(this_model)
  factors_vec3[i] <<- ncol(attr(terms(this_model), "factors"))
  fixef_vec3[i] <<- length(fixef(this_model))
})

.perf_df3 <- dplyr::bind_rows(performance_ls3)
model_comp_tbl3 <- tibble(names(model_ls3),
                          factors_vec3,
                          fixef_vec3,
                          round(.perf_df3[, 1]),
                          round(.perf_df3[, 2]),
                          round(.perf_df3[, 3], 2),
                          round(.perf_df3[, 4], 2),
                          round(.perf_df3[, 6], 2))
colnames(model_comp_tbl3) <- .model_comp_colnms

knitr::kable(model_comp_tbl)
knitr::kable(model_comp_tbl3)

print("Random effect of the dataset as compared to that of the participant:")
summary(marks_f_re_partcipant.data)
.resim <- REsim(marks_f_re_partcipant.data)
plotREsim(.resim)
.resim_data <- .resim %>%
  filter(groupFctr == "simulation") %>%
  arrange(mean)
print("Most difficult and easiest datasets:")
head(.resim_data)
tail(.resim_data)
```

## Marks by ... 

### Factor

```{r}
(marks_by_factor <-
   my_ggpubr(dat_qual,
             x = "factor", y = "marks",
             title = "Marks by factor"))
```

#### ... faceted by location

```{r}
(marks_by_factor_facet_location <-
   my_ggpubr_facet(dat_qual,
                   x = "factor", y = "marks",
                   facet = "location",
                   title = "Marks by factor, faceted on location"))
```

#### ... faceted by shape

```{r}
(marks_by_factor_facet_shape <-
   my_ggpubr_facet(dat_qual,
                   x = "factor", y = "marks",
                   facet = "shape",
                   title = "Marks by factor, faceted on shape"))
```

#### ... facet by order

```{r}
(marks_by_factor_facet_order <-
   my_ggpubr_facet(dat_qual,
                   x = "factor", y = "marks",
                   facet = "order",
                   title = "Marks by factor, faceted on order"))
```

#### ... facet by dimension

```{r}
(marks_by_factor_facet_dim <-
   my_ggpubr_facet(dat_qual,
                   x = "factor", y = "marks",
                   facet = "dim",
                   title = "Marks by factor, faceted on dimension"))
```

### Location, of signal mixing

```{r}
(marks_by_location <-
   my_ggpubr(dat_qual,
             x = "location", y = "marks",
             title = "Marks by location"))
```

### Order, of evaluation

```{r}
(marks_by_order <-
   my_ggpubr(dat_qual,
             x = "order", y = "marks",
             title = "Marks by evaluation order"))
# ## warning from: gg_pubr::stat_compare_means()
# Warning message:
# Computation failed in `stat_signif()`:
# missing value where TRUE/FALSE needed 
```

### Shape, variance-covariance 

```{r} 
(marks_by_shape <-
   my_ggpubr(dat_qual,
             x = "shape", y = "marks",
             title = "Marks by shape"))
```

### Dimension

```{r}
(marks_by_dim <-
   my_ggpubr(dat_qual,
             x = "dim", y = "marks",
             title = "Marks by dimension"))
```

<!-- ## Speed of response -->

<!-- ```{r} -->
<!-- (sec_last_resp_by_factor <- -->
<!--   my_ggpubr(dat_qual, -->
<!--             x = "factor", y = "seconds to last response", -->
<!--             title = "Seconds to last response by factor")) -->
<!-- (sec_last_resp_by_location <- -->
<!--   my_ggpubr(dat_qual, -->
<!--             x = "location", y = "seconds to last response", -->
<!--             title = "Seconds to last response by location")) -->
<!-- ``` -->

## Marginal effects of Survey variables

### Demographics

```{r}
# eval_survey
# skimr::skim(eval_survey)

# ## Not significant ##
# my_ggpubr(eval_survey,
#           x = "pronoun", y = "marks",
#           title = "Marks by pronoun")

## narrowly significant
marks_by_age <-
  my_ggpubr(eval_survey,
            x = "age", y = "marks",
            title = "Marks by age")
## narrowly not significant
marks_by_education <-
  my_ggpubr(eval_survey,
            x = "education", y = "marks",
            title = "Marks by education")
```


### Experience

```{r}
## Significant
marks_by_task_understanding <- eval_survey %>% rename(`task understanding` = task_understanding) %>% 
  my_ggpubr(x = "task understanding", y = "marks",
            title = "Marks by task understanding")
## Not significant ##
# my_ggpubr(eval_survey,
#           x = "data_viz_exp", y = "marks",
#           title = "Marks by data_viz_exp")
# my_ggpubr(eval_survey,
#           x = "analysis_exp", y = "marks",
#           title = "Marks by analysis_exp")
```


______

## Saving paper figures
```{r}
if(F){
  ## instance_id whitelist, the people kept for analysis. 
  #### (instance_id is: participant_num "_" perm_num "_" prolific_id)
  saveRDS(instance_id_whitelist,
          file = "./apps_supplementary/v4_prolifico_100/instance_id_whitelist.rds")
  
  
  ### dat_qual now saved inline with if(interactive()) ###
  .remove_y <- theme(axis.title.y = element_blank(),
                     axis.text.y = element_blank(),
                     axis.ticks.y = element_blank())
  .no_legend <- list(theme(legend.position = "off"),
                     ggtitle(NULL))
  gc()
  figMarksByMarg_notitle <- 
    cowplot::plot_grid(marks_by_factor + .no_legend + ggtitle(NULL),
                       marks_by_location + .remove_y + .no_legend,
                       marks_by_shape + .remove_y + .no_legend,
                       marks_by_order + .remove_y + .no_legend,
                       marks_by_dim + .remove_y + .no_legend,
                       ncol = 5, rel_widths = c(4, rep(3, 4)))
  title <- cowplot::ggdraw() +
    cowplot::draw_label("Marks by conditional block parameter",
                        x = .15, y = .6, hjust = .1, vjust = .5)
  gc()
  figMarksByMarg <- cowplot::plot_grid(title, figMarksByMarg_notitle,
                                       ncol = 1, rel_heights = c(0.1, 1))
  ggsave("figMarksByMarg.png", plot = figMarksByMarg, path = "./paper/figures",
         device = "png", width = 8, height = 3, unit = "in")
  gc()
  
  .no_legend <- 
    list(theme(legend.position = "off",
               axis.text.x = element_text(angle = 60, vjust = 1, hjust = 1)),
         ggtitle(NULL))
  ## Marginal survey data
  figMarksByMargSurvey_notitle <-
    cowplot::plot_grid(marks_by_task_understanding + .no_legend + ggtitle(waiver()),
                       marks_by_age + .remove_y + .no_legend,
                       marks_by_education + .remove_y + .no_legend,
                       ncol = 3, rel_widths = c(6, 5, 4))
  title <- cowplot::ggdraw() +
    cowplot::draw_label("Marks by conditional significant survey variable",
                        x = .15, y = .6, hjust = .1, vjust = .5)
  gc()
  figMarksByMargSurvey <-
    cowplot::plot_grid(title, figMarksByMargSurvey_notitle,
                       ncol = 1, rel_heights = c(0.1, 1))
  ggsave("figMarksByMargSurvey.png", plot = figMarksByMargSurvey, path = "./paper/figures",
         device = "png", width = 8, height = 4, unit = "in")
  gc()

  
  ## Model tables
  model_comp_tbl_ls <- list(models_eval = model_comp_tbl, 
                            models_survey = model_comp_tbl2, 
                            ext_models_eval.survey = model_comp_tbl3)
  saveRDS(model_comp_tbl_ls,
          file = "./paper/figures/model_comp_tbl_ls.rds")
  
  ## _Save model figure
  resim <- plotREsim(REsim(marks_f_re_partcipant.data))
  resid <- plot_residual(marks_f_re_partcipant.data)
  figModel_notitle <- cowplot::plot_grid(resid, resim, ncol = 2, rel_widths = c(3, 5))
  title <- cowplot::ggdraw() +
      cowplot::draw_label("marks^ = factor + effect(participant) + effect(simulation)",
                          x = .5, y = .75, hjust = .5, vjust = 1)
  (figModel <- cowplot::plot_grid(title, figModel_notitle,
                                  ncol = 1, rel_heights = c(0.1, 1)))
  ggsave("figModels.png", plot = figModel, path = "./paper/figures",
         device = "png", width = 8, height = 4, unit = "in")
}
```

