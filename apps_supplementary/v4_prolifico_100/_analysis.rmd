---
title: "prolifico 100"
author: "Nick Spyrison"
date: "11/03/2021"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
header-includes:
   - \usepackage{amsmath}
   - \usepackage{showframe}
editor_options: 
  chunk_output_type: console
---
```{r setup, include=FALSE}
library(tidyverse)
library("lme4")
library("merTools")

knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
rel_path <- function(rel_path = "."){
  rel_dir  <- dirname(rstudioapi::getSourceEditorContext()$path)
  rel_path <- paste0(rel_dir, "/", rel_path)
  normalizePath(rel_path, winslash = "/")
}

## Read from gsheets API4 and save local
if(F){
  ## Hash id of the google sheet
  ss_id <- "1K9qkMVRkrNO0vufofQJKWIJUyTys_8uVtEBdJBL_DzU" 
  raw <- googlesheets4::read_sheet(ss_id, sheet = 1L)
  ## Remove dummy rows
  raw <- raw %>% filter(!is.na(plot_active), ## dummy rows
                        !is.na(participant_num)) ## 2 missing participant_nums?
  ## Format 
  raw$full_perm_num = unlist(as.integer(raw$full_perm_num))
  raw$participant = unlist(as.character(raw$participant))
  dim(raw)
  saveRDS(raw, "./apps_supplementary/v4_prolifico_100/data/raw_prolific_100.rds")
}
## Load load and clean, save cleaned
if(F){
  raw <- readRDS(rel_path("data/raw_prolific_100.rds"))
  ## Only plot_active rows 
  ## AND Only participants (rows where nchar(participant) == 24 charcters long)
  dat_active <- raw %>% filter(plot_active == TRUE,
                               nchar(prolific_id) == 24L)
  source(file = rel_path("../../paper/R/clean_participant_data.r"),
         local = TRUE, echo = FALSE)
  ## pivot variables columns longer for task-grained aggregation.
  dat_longer <- dat_active %>% pivot_longer_resp_ans_tbl()
  ## Impute missing sec_to_resp, via mean diff with sec_on_pg
  .mean_diff <- mean(dat_longer$sec_on_pg, na.rm = TRUE) -
    mean(dat_longer$sec_to_resp, na.rm = TRUE)
  dat_longer <- dat_longer %>%
    mutate(sec_to_resp = dplyr::if_else(is.na(sec_to_resp), 
                                        sec_on_pg - .mean_diff, sec_to_resp))
  ## Aggregate to task grain.
  dat_task_agg <- aggregate_task_vars(dat_longer)
  ## Fix observeEvent() over count of radial input_inter. 
  dat_task_agg <- dat_task_agg %>% 
    dplyr::mutate(task_input_inter = dplyr::if_else(
      factor == "radial", task_input_inter -1L, task_input_inter))
  ## Plot friendly titles
  dat_task_agg <- dat_task_agg %>%
  rename(shape = vc, dim = p_dim, `evaluation order` = eval, participant = prolific_id,
         `is training` = is_training, `# response interactions` = task_resp_inter,
         `max seconds to respond` = max_sec_to_resp, `seconds on page` = max_sec_on_pg,
         `# of responses` = cnt_resp, marks = task_marks, 
         `parameter permutation` = full_perm_num)
  ## Save task aggregated data.
  saveRDS(dat_task_agg, rel_path("data/dat_task_agg_prolific_100.rds"))
}
## load aggregated data.
dat_task_agg <- readRDS(rel_path("data/dat_task_agg_prolific_100.rds"))


## Local functions -----
## For labeling n, mean on boxplots, following:
#### https://medium.com/@gscheithauer/how-to-add-number-of-observations-to-a-ggplot2-boxplot-b22710f7ef80
my_theme <- list(
  theme_minimal(),
  scale_color_brewer(palette = "Dark2"),
  scale_fill_brewer(palette = "Dark2"),
  geom_hline(yintercept = 0L),
  theme(legend.position = "bottom",
        legend.box = "vertical",
        legend.margin = margin(-6))
)
my_ggplot <- function(.aes = aes(x = `evaluation order`, y = marks,
                                 color = `is training`, fill = `is training`),
                      .title = "Default title",
                      .data = dat_qual)
{
  ggplot(.data, .aes) +
    labs(title = .title) +
    my_theme +
    geom_point(
      position = position_jitterdodge(jitter.width = .3, jitter.height = .05), alpha = .2) +
    geom_boxplot(position = "dodge", alpha = .4)
}
```

______


## Even-ness of evaluation

Let's look at the distribution of quality evaluations by full_perm_num.

```{r}
#### Aggregation tables

## participant_agg
participant_agg <- dat_qual %>% group_by(participant, `is training`) %>%
  summarise(n = n(),
            `full evaluations` = max(sum(`is training`) / 3, sum(!`is training`) / 6),
  ) %>% ungroup() %>% arrange(desc(`full evaluations`))

## perm_num_agg
perm_num_agg <- dat_qual %>% group_by(full_perm_num, `is training`) %>%
  summarise(n = n(),
            `full evaluations` = max(sum(`is training`) / 3, sum(!`is training`) / 6),
  ) %>% ungroup() %>% arrange(desc(`full evaluations`))

## app_instance_agg
app_intance_agg <- dat_qual %>% group_by(participant_num, full_perm_num, participant, `is training`) %>% arrange()
  summarise(instance_id = paste(sep = "_", participant_num, full_perm_num, participant),
            n = n(),
            `full evaluations` = max(sum(`is training`) / 3, sum(!`is training`) / 6),
  ) %>% ungroup() %>% arrange(desc(`full evaluations`))



#### Plot Evenness:

## Evaluations by participant
ggplot(participant_agg, aes(x = participant, y = even_studies, 
                         color = `is training`, fill = `is training`)) +
  labs(title = "Evaluations by participant") +
  my_theme + 
  geom_bar(stat = "identity", position = "dodge") + geom_hline(yintercept = 1) +
  geom_text(aes(x = .95 * max(length(unique(participant_agg$participant))), y = 1.2, 
                label = "ideal"), color = "black")

## Evaluations by parameter permutaion
.mn_val <- mean(perm_num_agg$even_studies)
(gg_eval_by_perm_num <- perm_num_agg %>% filter(`is training` == FALSE) %>% 
    ggplot(aes(x = `parameter permutation`, y = `full evaluations`,
               color = `is training`, fill = `is training`)) +
  labs(title = "Evaluations by parameter permutaion") +
  my_theme + 
  geom_bar(stat = "identity", position = "dodge") + 
  geom_hline(yintercept = .mn_val, linetype = 3) +
  geom_hline(yintercept = 3, linetype = 2) + 
  geom_text(aes(x = 30, y = 3.2, label = "target"), color = "black") +
  geom_text(aes(x = 26.5, y = .mn_val + .2, label = "mean of full evaluations"), color = "black")
)
```

```{r}



```


## Last response time density

I am concerned about the quality of the data, given that so many people experienced network issues. Let's explore.

```{r}
print(paste0("N_raw = ", length(unique(dat_task_agg$participant)), " unique prolific ids"))
lb <- quantile(dat_task_agg$`max seconds to respond`, probs = .25) ## bottom 25 %
ub <- quantile(dat_task_agg$`max seconds to respond`, probs = .95) ## top 5 %
ann_offset <- 7
ggplot() + 
  geom_density(aes(`max seconds to respond`, fill = ""), dat_task_agg, alpha = .5) +
  ggtitle("Seconds to respond density") +
  my_theme +
  lims(x = c(0, 100)) +
  geom_vline(xintercept = c(lb, ub), linetype = 2L) +
  geom_vline(xintercept = 60, linetype = 3L) +
  geom_label(aes(x = c(lb + ann_offset, 60 - ann_offset, ub - ann_offset), 
                 y = c(.05, .045, .05), 
                 label = c("25th percentile", "plot turns off" ,"95th percentile")
  )) +
  annotate("rect", xmin = -Inf, xmax = lb, ymin = -Inf, ymax = Inf,
           alpha = 0.3, fill = "firebrick1") +
  annotate("rect", xmin = lb, xmax = ub, ymin = -Inf, ymax = Inf,
           alpha = 0.3, fill = "aquamarine") +
  annotate("rect", xmin = ub, xmax = Inf, ymin = -Inf, ymax = Inf,
           alpha = 0.3, fill = "firebrick1")

dat_qual <- dat_task_agg 
#%>% filter(`max seconds to respond` > lb, `max seconds to respond` < ub)
## windsorized conflicts with the within participant evaluation.

#print(paste0("N_windsorized = ", length(unique(dat_qual$participant)), " unique prolific ids"))
obs_percent <- round(100L * nrow(dat_qual) / nrow(dat_task_agg), 2)
paste0("Percent of original task evaluations in subset: ", obs_percent, "%")
print("NOTE: The rest of the analysis we will be looking at this middle ~70% of the evaluations.")
```

```{r}
ggplot(dat_qual) + my_theme +
  geom_point(aes(`max seconds to respond`, marks,
                 fill = `is training`, color = `is training`), alpha = .2) +
  geom_smooth(aes(`max seconds to respond`, marks,
                  fill = `is training`, color = `is training`)) +
  ggtitle("Mark by last response time")
```


## Within-participants -- Marks by Evaluation order

```{r}
## Create a global unique id (guid), doesn't fix the issue, because the double counted t3 was from repeat 1_1 runs, on mar 4, remove it.

## instead we'll apply a simple filter
dat_qual_wi_participant <- dat_qual %>%
  filter(marks > -1L, marks < 1L)

  ggplot(dat_qual_wi_participant, 
            aes(x = factor, y = marks,
                frame = participant, group = participant,
                color = `is training`, fill = `is training`)
  ) +
  labs(title = "Within Participants, Marks by factor") +
  scale_color_brewer(palette = "Dark2") + 
  scale_fill_brewer(palette = "Dark2") +
  geom_line(alpha = .2)
  
  ### Looking at facets becomes too busy.
  # tgt_ids <- head(unique(dat_qual_wi_participant$participant))
  # dat_qual_wi_participant %>% 
  #   filter(participant %in% tgt_ids) %>% 
  #   ggplot(aes(x = `evaluation order`, y = marks,
  #              frame = frame_pro_id,
  #              group = frame_pro_id,
  #              color = `is training`, fill = `is training`)
  #   ) +
  #   labs(title = "Within Participants, Marks by evaluation order") +
  #   scale_color_brewer(palette = "Dark2") + 
  #   scale_fill_brewer(palette = "Dark2") +
  #   geom_point(aes(size = `# of responses`), alpha = .2) +
  #   geom_line(alpha = .2) + facet_grid(vars(participant))
  
print("Tried animating over participants, but erroring (Error in -data$group : invalid argument to unary operator) on a valid ggplot. Would be across the board with such low correlation")



cor_sec_to_resp <- cor(dat_qual_wi_participant$`max seconds to respond`,
                       dat_qual_wi_participant$marks) %>% round(3)
cor_eval <- cor(as.integer(dat_qual_wi_participant$`evaluation order`),
                dat_qual_wi_participant$marks) %>% round(3)
cor_cnt_resp <- cor(dat_qual_wi_participant$`seconds on page`, 
                    dat_qual_wi_participant$marks) %>% round(3)

print(paste0(
  "Quite busy, looking at the correlation, cor(evaluation order, marks) = ", cor_eval,
  ", a moderate negative value given that, cor(max time to respond, marks) = ", 
  cor_sec_to_resp
))




## Reviewing correlations, nothing too exciting, 
# corr_dat <- dat_qual %>%
#   mutate(`evaluation order` = as.numeric(`evaluation order`)) %>% 
#   dplyr::select(!z_weight_check)
# num_col_ind <- unlist(lapply(corr_dat, is.numeric))
# car_dat_mat <- corr_dat[, num_col_ind] %>% as.matrix() %>% cor()
# col3 <- colorRampPalette(c("blue", "white", "red"))
# corrplot::corrplot.mixed(car_dat_mat,
#                          lower.col = col3(100),
#                          upper.col = col3(100))
```


## Random effects regression model 

We'll first consider the baseline fixed effects considering only the continuous variables. We have:

$$
\begin{align*}
\widehat{marks} = ~
&\beta_{int} +
\beta_{SecResp} * SecResp +
\beta_{SecPg} * SecPg + 
\beta_{RespInter} * RespInter ~+ \\
&\beta_{CntResp} * CntResp +
\beta_{InputInter} * InputInter +
\epsilon
\end{align*}
$$
Where, 
$$\epsilon \sim \mathcal{N}(0,~\sigma)$$

Building on this, we add in vectors of all of our fixed factor terms: method factor, data dimension, variance-covariance shape, signal mixing location. Add a factor interaction to the number of input interactions as it is it intrinsically different based on the factor. Lastly we add the random effect of the participants. This random term, $effect_{participant}$, accounts for the difference between participant, that is the each individuals ability/disposition to effect their task marks. Then our mixed model is: 

$$
\begin{align*}
\widehat{marks} = ~
&\beta_{int} +
\beta_{SecResp} * SecResp +
\beta_{SecPg} * SecPg + 
\beta_{RespInter} * RespInter + \\
&\beta_{CntResp} * CntResp + 
\boldsymbol{\beta}_{InputInter*Factor} * InputInter * I(\boldsymbol{Factor}) +
\boldsymbol{\beta}_{factor} * I(\boldsymbol{factor}) + \\
&\boldsymbol{\beta}_{dim} * I(\boldsymbol{dim}) + 
\boldsymbol{\beta}_{shape} * I(\boldsymbol{shape}) + 
\boldsymbol{\beta}_{location} * I(\boldsymbol{location}) + 
\boldsymbol{\beta}_{participant} * \boldsymbol{effect}_{participant} +
\epsilon
\end{align*}
$$
where,  
$$
\begin{align*}
&\epsilon \sim \mathcal{N}(0,~\sigma) \\
&effect_{participant_i} \sim \mathcal{N}(0,~\sigma_{participant_i}) ~|~ i \in level(participant~ids)  \\
&factor \in (pca,~grand,~radial) \\
&dim \in (4,~6) \text{ variables, with 3 & 4 clusters respectively} \\
&shape \in (EEE,~EEV,~EVV~banana) \\
&location \in (0/100,~33/66,~50/50) \text{ % mixing of a noise and signal variable respectively} \\
&I() \text{ is the indicator function, a logical value for each level of the fixed factor}
&\end{align*}
$$



```{r}
## Mixed (fixed and random/variable) effects regression model,
### following along with:
if(F) 
  browseURL("https://m-clark.github.io/mixed-models-with-R/random_intercepts.html#running-a-mixed-model")
#install.packages("lme4")
dat_qual_onlyeval <- dat_qual %>% filter(`is training` == FALSE)

## The Models:

### 1) Start with simple terms of all variables

marks_lmer1 <- lmer( ## 15 terms remain after dropping 3 due to rank deficiency
  marks ~ 
    `max seconds to respond` + `seconds on page` + `# response interactions` + `# of responses` + task_input_inter * factor + ## Numeric, input_inter*factor interaction
    factor + dim + shape + location + `evaluation order` + ## Fixed factor random terms
    (1 | participant), ## Random effect
  data = dat_qual_onlyeval_renamed
)
aic_1 <- AIC(marks_lmer1)
print(paste0("Model 1) simple terms of all variables. 16 terms remain after dropping 4 due to rank deficiency, AIC = ", 
             round(aic_1, 0), "."))

### 2) remove the least bang for buck, 3 variables that are highly correlated, lose .1% AIC
marks_lmer2 <- lmer( ## 13 terms remain after dropping 3 due to rank deficiency
  marks ~
    `max seconds to respond` + `# response interactions` + task_input_inter * factor + ## Numeric
    factor + dim + shape + location + `evaluation order` + ## Fixed factor random terms
    (1 | participant), ## Random effect
  data = dat_qual_onlyeval_renamed
)
aic_2 <- AIC(marks_lmer2)
print("Model 2) simplify by removing 2 of the most correlated (redundant explaintion) numeric variables. We gain ~.2% AIC to remove 2 terms relative to the first model.")

### 3) Try to mix all terms of the simple model with factor
print("Model 3) we try to make an over complex model by starting with model 2, leave independant terms and introduce factor interactions. This costs 22 terms to improve AIC by 6.5%")
marks_lmer3 <- lmer( ## 35 terms remain after dropping 10 due to rank deficiency, 
  marks ~
    ## Independent
    `max seconds to respond` + `# response interactions` + task_input_inter + ## Numeric
    factor + dim * factor + shape + location + `evaluation order` + ## Fixed factor random terms
    (1 | participant) +
    ## factor interactions
    factor * (`max seconds to respond` + `seconds on page` + `# response interactions` + task_input_inter) + ## Numeric
    factor * (dim  + shape  + location + `evaluation order`) + ## Fixed factor random terms
    factor * (1 | participant), ## Random effect
  data = dat_qual_onlyeval_renamed
)
## Addition model warnings:
# Warning messages:
# 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
#   unable to evaluate scaled gradient
# 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
#   Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
aic_3 <- AIC(marks_lmer3)

# print("Confidence intervals:")
# confint(marks_lmer)
# 
# print("Head of participant effect:")
# coef(marks_lmer)$participant %>% head(5)
# 
# print("Prediction interval")
# predictInterval(marks_mixed_mod)   # for various model predictions, possibly with new data
# REsim(marks_mixed_mod)             # mean, median and sd of the random effect estimates

print("Let's take a closer look at model 2: \n summary:")
## Model summary
(s <- print(summary(marks_lmer2), digits = 3))

## Anova table
(a <- anova(marks_lmer2)) ## do we need t interact task_input_inter with factor (task_input_inter doesn't make sense for grand)?

## Residual plot
resid_2 <- data.frame(
  predicted  = predict(marks_lmer2), residual = residuals(marks_lmer2),
  factor = dat_qual_onlyeval_renamed$factor, 
  `# of responses` = dat_qual_onlyeval_renamed$`# of responses`,
  check.names = FALSE)
p <- ggplot(resid_2, aes(x = predicted, y = residual, color = factor, size = `# of responses`)) +
  geom_point(alpha = .2) + my_theme + ggtitle("Residuals by predcted values") + 
  theme(legend.position = "bottom",
        legend.box = "vertical",
        legend.margin = margin(-6))
(r <- ggExtra::ggMarginal(p, type = "density", fill = "grey80"))


## Random effects, as simulated from model posterior distributions
print("Random effect of participant, as simulated from the model posterior distributions")
(resim <- plotREsim(REsim(marks_lmer2)))  # plot the interval estimates
```


## Marks by ... 

### Factor

```{r}
(gg_marks_by_factor <- my_ggplot(
  .aes = aes(x = factor, y = marks,
             color = `is training`, fill = `is training`),
  .title = "Marks by factor",
  .data = dat_qual))
```

### Order, of evaluation

```{r}
(gg_marks_by_eval_order <- my_ggplot(.aes = aes(x = `evaluation order`, y = marks,
                     color = `is training`, fill = `is training`),
          .title = "Marks by evaluation order",
          .data = dat_qual))
```

### Shape, Variance-covariance 

```{r} 
(gg_marks_by_shape <- my_ggplot(aes(x = shape, y = marks,
              color = `is training`, fill = `is training`),
          "Marks by var-covariance",
          .data = dat_qual))
```

### Dimension

```{r}
(gg_marks_by_dim <- my_ggplot(aes(x = dim, y = marks,
              color = `is training`, fill = `is training`),
          "Marks by dimension",
          .data = dat_qual))
```

### Location, of signal mixing

```{r}
(gg_marks_by_location <- my_ggplot(aes(x = location, y = marks,
              color = `is training`, fill = `is training`),
          "Marks by location",
          .data = dat_qual))
```

#### Facet by factor

```{r}
my_ggplot(aes(x = location, y = marks,
              color = `is training`, fill = `is training`),
          "Marks by location, faceted by factor",
          .data = dat_qual) + facet_wrap(vars(factor))
```

#### Facet by covariance shape

```{r}
my_ggplot(aes(x = location, y = marks,
              color = `is training`, fill = `is training`),
          "Marks by location, faceted by covariance shape",
          .data = dat_qual) + 
  facet_wrap(vars(shape))
```

#### Facet by evaluation order

```{r}
my_ggplot(aes(x = location, y = marks,
              color = `is training`, fill = `is training`),
          "Marks by location, faceted by evaluation order",
          .data = dat_qual) + 
  facet_wrap(vars(`evaluation order`))
```

______

## Speed by factor, evaluation order

```{r}
my_ggplot(aes(x = factor, y = `max seconds to respond`,
              color = `is training`, fill = `is training`),
          "Seconds till last response by factor",
          .data = dat_qual) +
  coord_cartesian(ylim = c(0L, 70L))

my_ggplot(aes(x = `evaluation order`, y = `max seconds to respond`,
              color = `is training`, fill = `is training`),
          "Seconds till last response by evaluation order",
          .data = dat_qual) +
  coord_cartesian(ylim = c(0L, 70L))
```

______

## Input and response interactions

```{r}
my_ggplot(aes(x = factor, y = task_input_inter,
              color = `is training`, fill = `is training`),
          "Number of input interaction (throughness) by factor",
          .data = dat_qual) +
  coord_cartesian(ylim = c(0L, 30L))

my_ggplot(aes(x = factor, y = `# response interactions`,
              color = `is training`, fill = `is training`),
          "Number of response interaction (inverse confidence) by factor",
          .data = dat_qual)
```


## Manual saving
```{r}
if(F){
  
  gg_eval_by_perm_num ## evenness of perm num 
  gg_marks_by_factor
  gg_marks_by_eval_order
  gg_marks_by_shape
  gg_marks_by_dim
  gg_marks_by_location
  
  ## MODEL
  ## _Save model figures
  (figModel <- cowplot::plot_grid(r, resim, ncol = 2, rel_widths = c(3, 2)))
  ggsave("figModels.png", plot = figModel, path = "./paper/figures",
         device = "png", width = 8, height = 4, unit = "in")
  ## _Save model summary, annova, residual_df in as list.
  model_ls <- list(
    summary = s,
    anova = a,
    residual_df = resid_2
  )
  saveRDS(model_ls, file = "./paper/figures/model_ls.rds")
}

```